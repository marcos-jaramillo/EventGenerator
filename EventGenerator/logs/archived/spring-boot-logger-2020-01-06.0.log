2020-01-06 18:09:33,075 INFO org.springframework.boot.StartupInfoLogger [main] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 31584 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 18:09:33,079 INFO org.springframework.boot.SpringApplication [main] No active profile set, falling back to default profiles: default
2020-01-06 18:09:33,837 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 18:09:33,922 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Finished Spring Data repository scanning in 79ms. Found 2 repository interfaces.
2020-01-06 18:09:34,268 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [main] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 18:09:34,303 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 18:09:34,308 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 18:09:34,319 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 18:09:34,377 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:09:34,401 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$6bd67ee1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:09:34,407 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$47688a01] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:09:34,415 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$805032ce] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:09:34,421 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:09:35,595 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat initialized with port(s): 8081 (http)
2020-01-06 18:09:35,634 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 18:09:35,646 INFO org.apache.juli.logging.DirectJDKLog [main] Starting service [Tomcat]
2020-01-06 18:09:35,647 INFO org.apache.juli.logging.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 18:09:35,925 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2020-01-06 18:09:35,926 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 2756 ms
2020-01-06 18:09:39,262 INFO org.apache.spark.internal.Logging$class [main] Running Spark version 2.4.4
2020-01-06 18:09:39,469 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 18:09:39,650 INFO org.apache.spark.internal.Logging$class [main] Submitted application: test
2020-01-06 18:09:39,715 INFO org.apache.spark.internal.Logging$class [main] Changing view acls to: Marcos.Jaramillo
2020-01-06 18:09:39,716 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls to: Marcos.Jaramillo
2020-01-06 18:09:39,717 INFO org.apache.spark.internal.Logging$class [main] Changing view acls groups to: 
2020-01-06 18:09:39,718 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls groups to: 
2020-01-06 18:09:39,720 INFO org.apache.spark.internal.Logging$class [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 18:09:41,142 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'sparkDriver' on port 60530.
2020-01-06 18:09:41,162 INFO org.apache.spark.internal.Logging$class [main] Registering MapOutputTracker
2020-01-06 18:09:41,186 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManagerMaster
2020-01-06 18:09:41,190 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 18:09:41,191 INFO org.apache.spark.internal.Logging$class [main] BlockManagerMasterEndpoint up
2020-01-06 18:09:41,202 INFO org.apache.spark.internal.Logging$class [main] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-e6c3f9af-d53a-48bf-99b3-22af56b65818
2020-01-06 18:09:41,238 INFO org.apache.spark.internal.Logging$class [main] MemoryStore started with capacity 1992.0 MB
2020-01-06 18:09:41,256 INFO org.apache.spark.internal.Logging$class [main] Registering OutputCommitCoordinator
2020-01-06 18:09:41,336 INFO org.spark_project.jetty.util.log.Log [main] Logging initialized @10526ms
2020-01-06 18:09:41,418 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 18:09:41,437 INFO org.spark_project.jetty.server.Server [main] Started @10626ms
2020-01-06 18:09:41,466 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@5006a697{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 18:09:41,467 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'SparkUI' on port 4040.
2020-01-06 18:09:41,487 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@27c49f54{/jobs,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,488 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@62ff3028{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,489 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@45e68fac{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,490 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@684eb4a0{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,491 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@19a4cdea{/stages,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,492 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@434a2a10{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,493 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6debf1b8{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,494 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@722d3ddb{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,496 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@721fc228{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,497 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@25b87e1b{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,497 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@623a891d{/storage,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,498 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7962a364{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,499 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@756030e2{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,500 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@134ec0f3{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,500 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@258ac1e6{/environment,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,501 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@491f3fb0{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,502 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3d0ce151{/executors,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,502 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@58a0f75b{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,503 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2b569858{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,503 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1b84d03d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,508 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@41d8ac75{/static,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,509 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@30ce78e3{/,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,511 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@41041c31{/api,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,513 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@8bd9d08{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,514 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@189f3ccd{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 18:09:41,517 INFO org.apache.spark.internal.Logging$class [main] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 18:09:41,620 INFO org.apache.spark.internal.Logging$class [main] Starting executor ID driver on host localhost
2020-01-06 18:09:41,663 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60547.
2020-01-06 18:09:41,664 INFO org.apache.spark.internal.Logging$class [main] Server created on DESKTOP-8VGF145.mshome.net:60547
2020-01-06 18:09:41,667 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 18:09:41,705 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 60547, None)
2020-01-06 18:09:41,709 INFO org.apache.spark.internal.Logging$class [dispatcher-event-loop-0] Registering block manager DESKTOP-8VGF145.mshome.net:60547 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 60547, None)
2020-01-06 18:09:41,716 INFO org.apache.spark.internal.Logging$class [main] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 60547, None)
2020-01-06 18:09:41,717 INFO org.apache.spark.internal.Logging$class [main] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 60547, None)
2020-01-06 18:09:41,735 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@123d666b{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 18:09:42,959 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2020-01-06 18:09:42,960 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Adding discovered server localhost:27017 to client view of cluster
2020-01-06 18:09:43,056 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='5e13cc468e410b2cd27af61c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:13902}] to localhost:27017
2020-01-06 18:09:43,065 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='5e13cc468e410b2cd27af61c', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 2, 1]}, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=6152800}
2020-01-06 18:09:43,067 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='5e13cc468e410b2cd27af61c', description='null'}-localhost:27017] Discovered cluster type of STANDALONE
2020-01-06 18:09:43,172 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:09:43,180 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:09:43,182 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:09:43,183 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:09:43,292 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:09:43,293 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:09:43,293 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:09:43,293 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:09:43,980 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'applicationTaskExecutor'
2020-01-06 18:09:44,496 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'taskScheduler'
2020-01-06 18:09:44,784 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel nullChannel
2020-01-06 18:09:44,819 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel input
2020-01-06 18:09:44,998 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel output
2020-01-06 18:09:45,015 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel errorChannel
2020-01-06 18:09:45,097 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageHandler errorLogger
2020-01-06 18:09:45,136 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.input' has 1 subscriber(s).
2020-01-06 18:09:45,142 INFO org.springframework.integration.endpoint.EventDrivenConsumer [main] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 18:09:45,142 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.errorChannel' has 1 subscriber(s).
2020-01-06 18:09:45,142 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started _org.springframework.integration.errorLogger
2020-01-06 18:09:45,443 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Attempting to connect to: [localhost:5672]
2020-01-06 18:09:45,559 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Created new connection: rabbitConnectionFactory#11a8735d:0/SimpleConnection@64641bb2 [delegate=amqp://guest@127.0.0.1:5672/, localPort= 60549]
2020-01-06 18:09:45,654 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.output' has 1 subscriber(s).
2020-01-06 18:09:45,673 INFO org.springframework.cloud.stream.binder.rabbit.provisioning.RabbitExchangeQueueProvisioner [main] declaring queue for inbound: queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A, bound to: queue.log.messages
2020-01-06 18:09:45,717 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 1 subscriber(s).
2020-01-06 18:09:45,717 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 2 subscriber(s).
2020-01-06 18:09:45,745 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started inbound.queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A
2020-01-06 18:09:45,760 INFO org.apache.juli.logging.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-8081"]
2020-01-06 18:09:45,779 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat started on port(s): 8081 (http) with context path ''
2020-01-06 18:09:45,780 INFO org.springframework.boot.StartupInfoLogger [main] Started EventGeneratorApplication in 13.2678488 seconds (JVM running for 14.97)
2020-01-06 18:10:18,908 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:10:18,909 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-34-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:10:18,920 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Attempting to connect to: [localhost:5672]
2020-01-06 18:10:18,977 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Created new connection: rabbitConnectionFactory.publisher#5ff975d:0/SimpleConnection@76266e3d [delegate=amqp://guest@127.0.0.1:5672/, localPort= 60578]
2020-01-06 18:10:18,980 INFO org.springframework.amqp.rabbit.core.RabbitAdmin [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Auto-declaring a non-durable, auto-delete, or exclusive Queue (queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost.
2020-01-06 18:10:19,043 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-34-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:10:19,045 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-34-thread-1] SPARK Context Builded
2020-01-06 18:10:19,045 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-34-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:10:20,438 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/Proyectos/Translados/GitHub/mine/EventGenerator/EventGenerator/spark-warehouse').
2020-01-06 18:10:20,440 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Warehouse path is 'file:/D:/Proyectos/Translados/GitHub/mine/EventGenerator/EventGenerator/spark-warehouse'.
2020-01-06 18:10:20,448 INFO org.spark_project.jetty.server.handler.ContextHandler [pool-34-thread-1] Started o.s.j.s.ServletContextHandler@73fbd8f2{/SQL,null,AVAILABLE,@Spark}
2020-01-06 18:10:20,449 INFO org.spark_project.jetty.server.handler.ContextHandler [pool-34-thread-1] Started o.s.j.s.ServletContextHandler@36d01792{/SQL/json,null,AVAILABLE,@Spark}
2020-01-06 18:10:20,449 INFO org.spark_project.jetty.server.handler.ContextHandler [pool-34-thread-1] Started o.s.j.s.ServletContextHandler@6723c66f{/SQL/execution,null,AVAILABLE,@Spark}
2020-01-06 18:10:20,450 INFO org.spark_project.jetty.server.handler.ContextHandler [pool-34-thread-1] Started o.s.j.s.ServletContextHandler@51b5ca2d{/SQL/execution/json,null,AVAILABLE,@Spark}
2020-01-06 18:10:20,451 INFO org.spark_project.jetty.server.handler.ContextHandler [pool-34-thread-1] Started o.s.j.s.ServletContextHandler@33b9ef2d{/static/sql,null,AVAILABLE,@Spark}
2020-01-06 18:10:20,739 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Registered StateStoreCoordinator endpoint
2020-01-06 18:10:21,037 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Code generated in 241.3738 ms
2020-01-06 18:10:21,658 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Code generated in 11.0794 ms
2020-01-06 18:10:21,673 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Code generated in 6.1398 ms
2020-01-06 18:10:21,692 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-34-thread-1] data:=[value: string]
2020-01-06 18:10:21,693 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] Going to call the group FilterRules
2020-01-06 18:10:23,704 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:10:23,705 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-34-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:10:23,705 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] Going to call the group Translator
2020-01-06 18:10:23,774 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:10:23,774 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] Going to call the group Transformation
2020-01-06 18:10:24,175 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:10:24,236 INFO com.mongodb.diagnostics.logging.SLF4JLogger [pool-34-thread-1] Opened connection [connectionId{localValue:2, serverValue:13905}] to localhost:27017
2020-01-06 18:10:24,516 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-34-thread-1] Data Already Exist
2020-01-06 18:10:24,519 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-34-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:29,549 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:29,550 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-36-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:29,553 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-36-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:29,553 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-36-thread-1] SPARK Context Builded
2020-01-06 18:11:29,553 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-36-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:29,586 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-36-thread-1] data:=[value: string]
2020-01-06 18:11:29,586 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] Going to call the group FilterRules
2020-01-06 18:11:29,729 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:29,729 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-36-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:29,729 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] Going to call the group Translator
2020-01-06 18:11:29,927 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:29,928 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-37-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:29,935 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-37-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:29,936 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-37-thread-1] SPARK Context Builded
2020-01-06 18:11:29,936 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-37-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:29,970 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-37-thread-1] data:=[value: string]
2020-01-06 18:11:29,971 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] Going to call the group FilterRules
2020-01-06 18:11:30,094 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,095 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-38-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,100 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-38-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,100 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-38-thread-1] SPARK Context Builded
2020-01-06 18:11:30,100 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-38-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:30,134 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-38-thread-1] data:=[value: string]
2020-01-06 18:11:30,134 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] Going to call the group FilterRules
2020-01-06 18:11:30,277 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,279 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-39-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,284 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-39-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,285 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-39-thread-1] SPARK Context Builded
2020-01-06 18:11:30,286 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-39-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:30,326 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-39-thread-1] data:=[value: string]
2020-01-06 18:11:30,327 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] Going to call the group FilterRules
2020-01-06 18:11:30,418 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,419 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-40-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,422 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-40-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,422 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-40-thread-1] SPARK Context Builded
2020-01-06 18:11:30,422 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-40-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:30,465 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-40-thread-1] data:=[value: string]
2020-01-06 18:11:30,465 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] Going to call the group FilterRules
2020-01-06 18:11:30,522 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:30,522 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] Going to call the group Transformation
2020-01-06 18:11:30,581 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,582 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-41-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,585 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-41-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,586 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-41-thread-1] SPARK Context Builded
2020-01-06 18:11:30,586 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-41-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:30,621 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-41-thread-1] data:=[value: string]
2020-01-06 18:11:30,621 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] Going to call the group FilterRules
2020-01-06 18:11:30,749 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,750 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-42-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,753 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-42-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,753 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-42-thread-1] SPARK Context Builded
2020-01-06 18:11:30,753 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-42-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:30,777 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-42-thread-1] data:=[value: string]
2020-01-06 18:11:30,778 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-42-thread-1] Going to call the group FilterRules
2020-01-06 18:11:30,856 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:30,857 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-38-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,857 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] Going to call the group Translator
2020-01-06 18:11:30,857 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:30,857 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-37-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,858 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] Going to call the group Translator
2020-01-06 18:11:30,893 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:30,893 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-39-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,893 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] Going to call the group Translator
2020-01-06 18:11:30,919 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,920 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-43-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,922 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-43-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:30,923 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-43-thread-1] SPARK Context Builded
2020-01-06 18:11:30,923 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-43-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:30,948 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-43-thread-1] data:=[value: string]
2020-01-06 18:11:30,948 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-43-thread-1] Going to call the group FilterRules
2020-01-06 18:11:31,094 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,096 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-44-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,103 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-44-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,103 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-44-thread-1] SPARK Context Builded
2020-01-06 18:11:31,103 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-44-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:31,134 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-44-thread-1] data:=[value: string]
2020-01-06 18:11:31,135 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-44-thread-1] Going to call the group FilterRules
2020-01-06 18:11:31,256 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,257 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-45-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,264 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-45-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,264 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-45-thread-1] SPARK Context Builded
2020-01-06 18:11:31,264 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-45-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:31,312 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-45-thread-1] data:=[value: string]
2020-01-06 18:11:31,313 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-45-thread-1] Going to call the group FilterRules
2020-01-06 18:11:31,413 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,414 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-46-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,419 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-46-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,420 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-46-thread-1] SPARK Context Builded
2020-01-06 18:11:31,420 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-46-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:31,444 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:31,445 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-40-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,445 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] Going to call the group Translator
2020-01-06 18:11:31,460 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-46-thread-1] data:=[value: string]
2020-01-06 18:11:31,460 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-46-thread-1] Going to call the group FilterRules
2020-01-06 18:11:31,586 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,587 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-47-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,592 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-47-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,592 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-47-thread-1] SPARK Context Builded
2020-01-06 18:11:31,592 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-47-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:11:31,630 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-47-thread-1] data:=[value: string]
2020-01-06 18:11:31,630 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-47-thread-1] Going to call the group FilterRules
2020-01-06 18:11:31,699 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:31,700 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] Going to call the group Transformation
2020-01-06 18:11:31,700 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-42-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:31,700 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-42-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,700 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-42-thread-1] Going to call the group Translator
2020-01-06 18:11:31,707 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:31,708 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] Going to call the group Transformation
2020-01-06 18:11:31,717 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:31,720 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-36-thread-1] Data Already Exist
2020-01-06 18:11:31,720 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-36-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:31,733 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-46-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:31,733 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-46-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,734 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-46-thread-1] Going to call the group Translator
2020-01-06 18:11:31,797 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:31,797 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] Going to call the group Transformation
2020-01-06 18:11:31,827 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-45-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:31,828 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-45-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,828 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-45-thread-1] Going to call the group Translator
2020-01-06 18:11:31,847 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:31,849 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-37-thread-1] Data Already Exist
2020-01-06 18:11:31,850 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-37-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:31,888 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:31,888 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-41-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:31,889 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] Going to call the group Translator
2020-01-06 18:11:32,102 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,102 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] Going to call the group Transformation
2020-01-06 18:11:32,102 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-43-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,102 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-43-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:32,103 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-43-thread-1] Going to call the group Translator
2020-01-06 18:11:32,351 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:32,354 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,354 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] Going to call the group Transformation
2020-01-06 18:11:32,354 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-45-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,354 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-45-thread-1] Going to call the group TopicAssignment
2020-01-06 18:11:32,358 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-40-thread-1] Data Already Exist
2020-01-06 18:11:32,358 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-40-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:32,359 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-47-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,359 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-47-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:32,360 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-47-thread-1] Going to call the group Translator
2020-01-06 18:11:32,360 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-43-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,361 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-43-thread-1] Going to call the group Transformation
2020-01-06 18:11:32,359 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:32,360 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-42-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,363 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-42-thread-1] Going to call the group Transformation
2020-01-06 18:11:32,371 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-46-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,371 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-46-thread-1] Going to call the group Transformation
2020-01-06 18:11:32,371 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-44-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,371 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-44-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:11:32,372 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-44-thread-1] Going to call the group Translator
2020-01-06 18:11:32,374 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-38-thread-1] Data Already Exist
2020-01-06 18:11:32,375 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-38-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:32,381 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:32,388 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-43-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:32,389 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-39-thread-1] Data Already Exist
2020-01-06 18:11:32,389 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-39-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:32,392 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-47-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,393 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-47-thread-1] Going to call the group Transformation
2020-01-06 18:11:32,395 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-43-thread-1] Data Already Exist
2020-01-06 18:11:32,395 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-43-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:32,399 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-46-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:32,404 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-46-thread-1] Data Already Exist
2020-01-06 18:11:32,405 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-46-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:32,408 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:32,409 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-44-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,409 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-44-thread-1] Going to call the group Transformation
2020-01-06 18:11:32,411 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-41-thread-1] Data Already Exist
2020-01-06 18:11:32,412 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-41-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:32,488 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-47-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:32,490 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-47-thread-1] Data Already Exist
2020-01-06 18:11:32,490 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-42-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:32,491 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-47-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:32,493 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-42-thread-1] Data Already Exist
2020-01-06 18:11:32,493 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-42-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:32,494 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-45-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:11:32,495 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-45-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.EventNotFoundException: Error while validate the Event for 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	} from rule  TopicAssignment
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:110)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:11:32,626 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-44-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:11:32,629 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-44-thread-1] Data Already Exist
2020-01-06 18:11:32,629 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-44-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:37)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:12:46,449 INFO org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin [RMI TCP Connection(3)-127.0.0.1] Application shutdown requested.
2020-01-06 18:12:46,507 INFO org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer [RMI TCP Connection(3)-127.0.0.1] Waiting for workers to finish.
2020-01-06 18:12:46,640 INFO org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer [RMI TCP Connection(3)-127.0.0.1] Successfully waited for workers to finish.
2020-01-06 18:12:46,641 INFO org.springframework.integration.endpoint.AbstractEndpoint [RMI TCP Connection(3)-127.0.0.1] stopped inbound.queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A
2020-01-06 18:12:46,652 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [RMI TCP Connection(3)-127.0.0.1] Registering MessageChannel queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A.errors
2020-01-06 18:12:46,804 INFO org.springframework.integration.channel.AbstractSubscribableChannel [RMI TCP Connection(3)-127.0.0.1] Channel 'application.queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A.errors' has 1 subscriber(s).
2020-01-06 18:12:46,805 INFO org.springframework.integration.channel.AbstractSubscribableChannel [RMI TCP Connection(3)-127.0.0.1] Channel 'application.queue.log.messages.anonymous.-GLqgpqETOWu9AAq7l4i2A.errors' has 0 subscriber(s).
2020-01-06 18:12:46,809 INFO org.springframework.integration.endpoint.EventDrivenConsumer [RMI TCP Connection(3)-127.0.0.1] Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 18:12:46,810 INFO org.springframework.integration.channel.AbstractSubscribableChannel [RMI TCP Connection(3)-127.0.0.1] Channel 'application.errorChannel' has 0 subscriber(s).
2020-01-06 18:12:46,810 INFO org.springframework.integration.endpoint.AbstractEndpoint [RMI TCP Connection(3)-127.0.0.1] stopped _org.springframework.integration.errorLogger
2020-01-06 18:12:46,810 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [RMI TCP Connection(3)-127.0.0.1] Shutting down ExecutorService 'taskScheduler'
2020-01-06 18:12:46,860 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [RMI TCP Connection(3)-127.0.0.1] Shutting down ExecutorService 'applicationTaskExecutor'
2020-01-06 18:12:46,869 INFO com.mongodb.diagnostics.logging.SLF4JLogger [RMI TCP Connection(3)-127.0.0.1] Closed connection [connectionId{localValue:2, serverValue:13905}] to localhost:27017 because the pool has been closed.
2020-01-06 18:12:46,886 INFO org.spark_project.jetty.server.AbstractConnector [RMI TCP Connection(3)-127.0.0.1] Stopped Spark@5006a697{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 18:12:46,888 INFO org.apache.spark.internal.Logging$class [RMI TCP Connection(3)-127.0.0.1] Stopped Spark web UI at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 18:12:46,910 INFO org.apache.spark.internal.Logging$class [dispatcher-event-loop-0] MapOutputTrackerMasterEndpoint stopped!
2020-01-06 18:12:46,922 INFO org.apache.spark.internal.Logging$class [RMI TCP Connection(3)-127.0.0.1] MemoryStore cleared
2020-01-06 18:12:46,923 INFO org.apache.spark.internal.Logging$class [RMI TCP Connection(3)-127.0.0.1] BlockManager stopped
2020-01-06 18:12:46,925 INFO org.apache.spark.internal.Logging$class [RMI TCP Connection(3)-127.0.0.1] BlockManagerMaster stopped
2020-01-06 18:12:46,931 INFO org.apache.spark.internal.Logging$class [dispatcher-event-loop-0] OutputCommitCoordinator stopped!
2020-01-06 18:12:46,936 INFO org.apache.spark.internal.Logging$class [RMI TCP Connection(3)-127.0.0.1] Successfully stopped SparkContext
2020-01-06 18:12:46,937 INFO org.apache.spark.internal.Logging$class [RMI TCP Connection(3)-127.0.0.1] SparkContext already stopped.
2020-01-06 18:12:46,939 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [RMI TCP Connection(3)-127.0.0.1] Summary on shutdown: nullChannel
2020-01-06 18:12:46,939 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [RMI TCP Connection(3)-127.0.0.1] Summary on shutdown: input
2020-01-06 18:12:46,939 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [RMI TCP Connection(3)-127.0.0.1] Summary on shutdown: output
2020-01-06 18:12:46,939 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [RMI TCP Connection(3)-127.0.0.1] Summary on shutdown: errorChannel
2020-01-06 18:12:46,939 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [RMI TCP Connection(3)-127.0.0.1] Summary on shutdown: _org.springframework.integration.errorLogger.handler
2020-01-06 18:12:59,129 ERROR org.springframework.boot.SpringApplication [main] Application run failed
java.lang.IllegalStateException: Logback configuration error detected: 
ERROR in ch.qos.logback.core.pattern.parser.Compiler@16ecee1 - There is no conversion class registered for conversion word [tid]
ERROR in ch.qos.logback.core.pattern.parser.Compiler@16ecee1 - [tid] is not a valid conversion word
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.loadConfiguration(LogbackLoggingSystem.java:167)
	at org.springframework.boot.logging.AbstractLoggingSystem.initializeWithConventions(AbstractLoggingSystem.java:80)
	at org.springframework.boot.logging.AbstractLoggingSystem.initialize(AbstractLoggingSystem.java:60)
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.initialize(LogbackLoggingSystem.java:118)
	at org.springframework.boot.context.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:289)
	at org.springframework.boot.context.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:264)
	at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:226)
	at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:203)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:127)
	at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:76)
	at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:53)
	at org.springframework.boot.SpringApplication.prepareEnvironment(SpringApplication.java:342)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:305)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1204)
	at com.ternium.core.eventgenerator.EventGeneratorApplication.main(EventGeneratorApplication.java:27)
2020-01-06 18:18:41,971 INFO org.springframework.boot.StartupInfoLogger [main] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 20524 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 18:18:41,975 INFO org.springframework.boot.SpringApplication [main] No active profile set, falling back to default profiles: default
2020-01-06 18:18:42,718 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 18:18:42,801 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Finished Spring Data repository scanning in 77ms. Found 2 repository interfaces.
2020-01-06 18:18:43,151 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [main] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 18:18:43,195 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 18:18:43,200 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 18:18:43,210 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 18:18:43,267 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:18:43,294 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$43372c77] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:18:43,300 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$1ec93797] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:18:43,309 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$57b0e064] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:18:43,316 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:18:43,629 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat initialized with port(s): 8081 (http)
2020-01-06 18:18:43,642 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 18:18:43,650 INFO org.apache.juli.logging.DirectJDKLog [main] Starting service [Tomcat]
2020-01-06 18:18:43,651 INFO org.apache.juli.logging.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 18:18:43,909 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2020-01-06 18:18:43,910 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 1833 ms
2020-01-06 18:18:46,704 INFO org.apache.spark.internal.Logging$class [main] Running Spark version 2.4.4
2020-01-06 18:18:46,857 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 18:18:46,947 INFO org.apache.spark.internal.Logging$class [main] Submitted application: test
2020-01-06 18:18:47,008 INFO org.apache.spark.internal.Logging$class [main] Changing view acls to: Marcos.Jaramillo
2020-01-06 18:18:47,009 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls to: Marcos.Jaramillo
2020-01-06 18:18:47,010 INFO org.apache.spark.internal.Logging$class [main] Changing view acls groups to: 
2020-01-06 18:18:47,012 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls groups to: 
2020-01-06 18:18:47,014 INFO org.apache.spark.internal.Logging$class [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 18:18:48,235 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'sparkDriver' on port 61616.
2020-01-06 18:18:48,252 INFO org.apache.spark.internal.Logging$class [main] Registering MapOutputTracker
2020-01-06 18:18:48,278 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManagerMaster
2020-01-06 18:18:48,282 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 18:18:48,283 INFO org.apache.spark.internal.Logging$class [main] BlockManagerMasterEndpoint up
2020-01-06 18:18:48,289 INFO org.apache.spark.internal.Logging$class [main] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-13a95dc2-0769-4d80-aafc-4bd346f2be0e
2020-01-06 18:18:48,311 INFO org.apache.spark.internal.Logging$class [main] MemoryStore started with capacity 1992.0 MB
2020-01-06 18:18:48,330 INFO org.apache.spark.internal.Logging$class [main] Registering OutputCommitCoordinator
2020-01-06 18:18:48,405 INFO org.spark_project.jetty.util.log.Log [main] Logging initialized @8438ms
2020-01-06 18:18:48,474 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 18:18:48,490 INFO org.spark_project.jetty.server.Server [main] Started @8524ms
2020-01-06 18:18:48,515 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@428e9be2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 18:18:48,516 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'SparkUI' on port 4040.
2020-01-06 18:18:48,535 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7cf166db{/jobs,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,536 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@609edb55{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,536 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@147892be{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,537 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@23e1f610{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,538 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@73dc7db0{/stages,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,538 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1a3a6216{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,539 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@319ea996{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,540 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@193c810{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,541 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1ef7e4c7{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,542 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@57edfa89{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,542 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6c0bf8f4{/storage,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,543 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@73476e2d{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,544 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@52b77d5e{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,544 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6ab6ec33{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,545 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@594965c9{/environment,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,545 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@11b74ecb{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,546 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@78839c2e{/executors,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,547 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@25093079{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,548 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@37fc7e3c{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,549 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1c96bf1e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,555 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7890324e{/static,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,556 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6f70015{/,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,558 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1d5fc340{/api,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,559 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6e21c6ed{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,560 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@75c30a4f{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 18:18:48,563 INFO org.apache.spark.internal.Logging$class [main] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 18:18:48,651 INFO org.apache.spark.internal.Logging$class [main] Starting executor ID driver on host localhost
2020-01-06 18:18:48,683 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61633.
2020-01-06 18:18:48,684 INFO org.apache.spark.internal.Logging$class [main] Server created on DESKTOP-8VGF145.mshome.net:61633
2020-01-06 18:18:48,686 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 18:18:48,713 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 61633, None)
2020-01-06 18:18:48,717 INFO org.apache.spark.internal.Logging$class [dispatcher-event-loop-0] Registering block manager DESKTOP-8VGF145.mshome.net:61633 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 61633, None)
2020-01-06 18:18:48,722 INFO org.apache.spark.internal.Logging$class [main] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 61633, None)
2020-01-06 18:18:48,723 INFO org.apache.spark.internal.Logging$class [main] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 61633, None)
2020-01-06 18:18:48,738 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2472ba04{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 18:18:49,760 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2020-01-06 18:18:49,761 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Adding discovered server localhost:27017 to client view of cluster
2020-01-06 18:18:49,842 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='5e13ce6957823433178ea007', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:13921}] to localhost:27017
2020-01-06 18:18:49,851 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='5e13ce6957823433178ea007', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 2, 1]}, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=5607000}
2020-01-06 18:18:49,853 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='5e13ce6957823433178ea007', description='null'}-localhost:27017] Discovered cluster type of STANDALONE
2020-01-06 18:18:49,934 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:18:49,940 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:18:49,941 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:18:49,942 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:18:50,049 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:18:50,050 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:18:50,051 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:18:50,051 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:18:50,594 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'applicationTaskExecutor'
2020-01-06 18:18:51,006 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'taskScheduler'
2020-01-06 18:18:51,266 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel errorChannel
2020-01-06 18:18:51,388 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel nullChannel
2020-01-06 18:18:51,413 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel input
2020-01-06 18:18:51,468 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel output
2020-01-06 18:18:51,479 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageHandler errorLogger
2020-01-06 18:18:51,517 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.input' has 1 subscriber(s).
2020-01-06 18:18:51,523 INFO org.springframework.integration.endpoint.EventDrivenConsumer [main] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 18:18:51,523 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.errorChannel' has 1 subscriber(s).
2020-01-06 18:18:51,523 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started _org.springframework.integration.errorLogger
2020-01-06 18:18:51,789 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Attempting to connect to: [localhost:5672]
2020-01-06 18:18:51,852 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Created new connection: rabbitConnectionFactory#561e8bab:0/SimpleConnection@3d1b91d1 [delegate=amqp://guest@127.0.0.1:5672/, localPort= 61636]
2020-01-06 18:18:51,953 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.output' has 1 subscriber(s).
2020-01-06 18:18:52,000 INFO org.springframework.cloud.stream.binder.rabbit.provisioning.RabbitExchangeQueueProvisioner [main] declaring queue for inbound: queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ, bound to: queue.log.messages
2020-01-06 18:18:52,064 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 1 subscriber(s).
2020-01-06 18:18:52,064 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 2 subscriber(s).
2020-01-06 18:18:52,105 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started inbound.queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ
2020-01-06 18:18:52,134 INFO org.apache.juli.logging.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-8081"]
2020-01-06 18:18:52,164 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat started on port(s): 8081 (http) with context path ''
2020-01-06 18:18:52,166 INFO org.springframework.boot.StartupInfoLogger [main] Started EventGeneratorApplication in 10.8418972 seconds (JVM running for 12.199)
2020-01-06 18:19:16,858 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:16,859 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-34-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:16,870 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ-1] Attempting to connect to: [localhost:5672]
2020-01-06 18:19:16,879 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ-1] Created new connection: rabbitConnectionFactory.publisher#5f08688b:0/SimpleConnection@3ad84f87 [delegate=amqp://guest@127.0.0.1:5672/, localPort= 61659]
2020-01-06 18:19:16,880 INFO org.springframework.amqp.rabbit.core.RabbitAdmin [queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ-1] Auto-declaring a non-durable, auto-delete, or exclusive Queue (queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost.
2020-01-06 18:19:16,935 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-34-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:16,936 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-34-thread-1] SPARK Context Builded
2020-01-06 18:19:16,937 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-34-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:19:18,353 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/Proyectos/Translados/GitHub/mine/EventGenerator/EventGenerator/spark-warehouse').
2020-01-06 18:19:18,354 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Warehouse path is 'file:/D:/Proyectos/Translados/GitHub/mine/EventGenerator/EventGenerator/spark-warehouse'.
2020-01-06 18:19:18,364 INFO org.spark_project.jetty.server.handler.ContextHandler [pool-34-thread-1] Started o.s.j.s.ServletContextHandler@215f436b{/SQL,null,AVAILABLE,@Spark}
2020-01-06 18:19:18,365 INFO org.spark_project.jetty.server.handler.ContextHandler [pool-34-thread-1] Started o.s.j.s.ServletContextHandler@30a5615f{/SQL/json,null,AVAILABLE,@Spark}
2020-01-06 18:19:18,366 INFO org.spark_project.jetty.server.handler.ContextHandler [pool-34-thread-1] Started o.s.j.s.ServletContextHandler@79ce9ba4{/SQL/execution,null,AVAILABLE,@Spark}
2020-01-06 18:19:18,367 INFO org.spark_project.jetty.server.handler.ContextHandler [pool-34-thread-1] Started o.s.j.s.ServletContextHandler@39c12a20{/SQL/execution/json,null,AVAILABLE,@Spark}
2020-01-06 18:19:18,370 INFO org.spark_project.jetty.server.handler.ContextHandler [pool-34-thread-1] Started o.s.j.s.ServletContextHandler@37ad99d8{/static/sql,null,AVAILABLE,@Spark}
2020-01-06 18:19:18,711 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Registered StateStoreCoordinator endpoint
2020-01-06 18:19:18,982 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Code generated in 219.4383 ms
2020-01-06 18:19:21,430 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Code generated in 12.0143 ms
2020-01-06 18:19:21,446 INFO org.apache.spark.internal.Logging$class [pool-34-thread-1] Code generated in 6.49 ms
2020-01-06 18:19:21,463 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-34-thread-1] data:=[value: string]
2020-01-06 18:19:21,465 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] Going to call the group FilterRules
2020-01-06 18:19:21,888 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:21,888 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-34-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:21,888 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] Going to call the group Translator
2020-01-06 18:19:21,905 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:21,905 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] Going to call the group Transformation
2020-01-06 18:19:21,923 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-34-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:19:22,002 INFO com.mongodb.diagnostics.logging.SLF4JLogger [pool-34-thread-1] Opened connection [connectionId{localValue:2, serverValue:13923}] to localhost:27017
2020-01-06 18:19:22,040 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-34-thread-1] Data Already Exist
2020-01-06 18:19:22,043 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-34-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:42)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:19:26,917 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:26,919 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-36-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:26,922 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-36-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:26,923 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-36-thread-1] SPARK Context Builded
2020-01-06 18:19:26,923 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-36-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:19:26,956 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-36-thread-1] data:=[value: string]
2020-01-06 18:19:26,956 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] Going to call the group FilterRules
2020-01-06 18:19:26,977 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:26,978 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-36-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:26,978 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] Going to call the group Translator
2020-01-06 18:19:26,993 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:26,994 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] Going to call the group Transformation
2020-01-06 18:19:27,088 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,089 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-37-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,092 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-37-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,092 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-37-thread-1] SPARK Context Builded
2020-01-06 18:19:27,093 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-37-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:19:27,122 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-37-thread-1] data:=[value: string]
2020-01-06 18:19:27,122 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] Going to call the group FilterRules
2020-01-06 18:19:27,252 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,253 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-38-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,257 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-38-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,257 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-38-thread-1] SPARK Context Builded
2020-01-06 18:19:27,257 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-38-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:19:27,285 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-38-thread-1] data:=[value: string]
2020-01-06 18:19:27,285 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] Going to call the group FilterRules
2020-01-06 18:19:27,410 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,411 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-39-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,414 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-39-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,415 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-39-thread-1] SPARK Context Builded
2020-01-06 18:19:27,415 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-39-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:19:27,441 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-39-thread-1] data:=[value: string]
2020-01-06 18:19:27,441 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] Going to call the group FilterRules
2020-01-06 18:19:27,573 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,574 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-40-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,577 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-40-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,578 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-40-thread-1] SPARK Context Builded
2020-01-06 18:19:27,578 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-40-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:19:27,603 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-40-thread-1] data:=[value: string]
2020-01-06 18:19:27,603 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] Going to call the group FilterRules
2020-01-06 18:19:27,738 INFO com.ternium.core.eventgenerator.stream.RabbitStream [queue.log.messages.anonymous.lWNSDNdFTCSLYVboCAGSbQ-1] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,739 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [pool-41-thread-1] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,742 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-41-thread-1] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:27,742 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-41-thread-1] SPARK Context Builded
2020-01-06 18:19:27,742 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-41-thread-1] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:19:27,767 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [pool-41-thread-1] data:=[value: string]
2020-01-06 18:19:27,767 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] Going to call the group FilterRules
2020-01-06 18:19:28,591 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:28,593 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-36-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:19:28,605 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:28,605 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:28,605 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:28,699 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:28,914 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-37-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:28,914 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-39-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:28,914 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-41-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:28,914 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-38-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:28,914 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-40-thread-1] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:19:28,915 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] Going to call the group Translator
2020-01-06 18:19:28,915 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] Going to call the group Translator
2020-01-06 18:19:28,915 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] Going to call the group Translator
2020-01-06 18:19:28,915 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] Going to call the group Translator
2020-01-06 18:19:28,915 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] Going to call the group Translator
2020-01-06 18:19:28,971 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-36-thread-1] Data Already Exist
2020-01-06 18:19:28,971 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-36-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:42)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:19:29,001 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:29,002 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] Going to call the group Transformation
2020-01-06 18:19:29,013 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:29,013 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] Going to call the group Transformation
2020-01-06 18:19:29,014 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:29,014 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] Going to call the group Transformation
2020-01-06 18:19:29,017 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:29,017 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] Going to call the group Transformation
2020-01-06 18:19:29,018 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:19:29,018 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] Going to call the group Transformation
2020-01-06 18:19:29,035 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-37-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:19:29,044 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-40-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:19:29,045 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-37-thread-1] Data Already Exist
2020-01-06 18:19:29,045 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-37-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:42)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:19:29,047 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-40-thread-1] Data Already Exist
2020-01-06 18:19:29,047 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-40-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:42)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:19:29,050 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-39-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:19:29,053 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-38-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:19:29,054 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-39-thread-1] Data Already Exist
2020-01-06 18:19:29,054 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-39-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:42)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:19:29,057 INFO com.mongodb.diagnostics.logging.SLF4JLogger [pool-38-thread-1] Opened connection [connectionId{localValue:3, serverValue:13925}] to localhost:27017
2020-01-06 18:19:29,059 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-38-thread-1] Data Already Exist
2020-01-06 18:19:29,060 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-38-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:42)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:19:29,061 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [pool-41-thread-1] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:19:29,063 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [pool-41-thread-1] Data Already Exist
2020-01-06 18:19:29,063 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [pool-41-thread-1] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:42)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:26:43,076 INFO org.springframework.boot.StartupInfoLogger [] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 25200 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 18:26:43,081 INFO org.springframework.boot.SpringApplication [] No active profile set, falling back to default profiles: default
2020-01-06 18:26:43,979 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 18:26:44,057 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [] Finished Spring Data repository scanning in 71ms. Found 2 repository interfaces.
2020-01-06 18:26:44,357 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 18:26:44,391 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 18:26:44,396 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 18:26:44,410 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 18:26:44,474 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:26:44,502 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$87c414c7] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:26:44,507 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$63561fe7] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:26:44,515 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$9c3dc8b4] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:26:44,520 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:26:44,807 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [] Tomcat initialized with port(s): 8081 (http)
2020-01-06 18:26:44,822 INFO org.apache.juli.logging.DirectJDKLog [] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 18:26:44,833 INFO org.apache.juli.logging.DirectJDKLog [] Starting service [Tomcat]
2020-01-06 18:26:44,834 INFO org.apache.juli.logging.DirectJDKLog [] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 18:26:45,102 INFO org.apache.juli.logging.DirectJDKLog [] Initializing Spring embedded WebApplicationContext
2020-01-06 18:26:45,102 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [] Root WebApplicationContext: initialization completed in 1940 ms
2020-01-06 18:26:47,756 INFO org.apache.spark.internal.Logging$class [] Running Spark version 2.4.4
2020-01-06 18:26:47,911 WARN org.apache.hadoop.util.NativeCodeLoader [] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 18:26:47,984 INFO org.apache.spark.internal.Logging$class [] Submitted application: test
2020-01-06 18:26:48,043 INFO org.apache.spark.internal.Logging$class [] Changing view acls to: Marcos.Jaramillo
2020-01-06 18:26:48,044 INFO org.apache.spark.internal.Logging$class [] Changing modify acls to: Marcos.Jaramillo
2020-01-06 18:26:48,046 INFO org.apache.spark.internal.Logging$class [] Changing view acls groups to: 
2020-01-06 18:26:48,048 INFO org.apache.spark.internal.Logging$class [] Changing modify acls groups to: 
2020-01-06 18:26:48,049 INFO org.apache.spark.internal.Logging$class [] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 18:26:49,195 INFO org.apache.spark.internal.Logging$class [] Successfully started service 'sparkDriver' on port 62439.
2020-01-06 18:26:49,215 INFO org.apache.spark.internal.Logging$class [] Registering MapOutputTracker
2020-01-06 18:26:49,238 INFO org.apache.spark.internal.Logging$class [] Registering BlockManagerMaster
2020-01-06 18:26:49,242 INFO org.apache.spark.internal.Logging$class [] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 18:26:49,242 INFO org.apache.spark.internal.Logging$class [] BlockManagerMasterEndpoint up
2020-01-06 18:26:49,251 INFO org.apache.spark.internal.Logging$class [] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-b7fe6ae9-6c90-455f-b8a5-76be8f95b00a
2020-01-06 18:26:49,277 INFO org.apache.spark.internal.Logging$class [] MemoryStore started with capacity 1992.0 MB
2020-01-06 18:26:49,294 INFO org.apache.spark.internal.Logging$class [] Registering OutputCommitCoordinator
2020-01-06 18:26:49,360 INFO org.spark_project.jetty.util.log.Log [] Logging initialized @8748ms
2020-01-06 18:26:49,437 INFO org.spark_project.jetty.server.Server [] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 18:26:49,458 INFO org.spark_project.jetty.server.Server [] Started @8846ms
2020-01-06 18:26:49,483 INFO org.spark_project.jetty.server.AbstractConnector [] Started ServerConnector@735b1ad2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 18:26:49,484 INFO org.apache.spark.internal.Logging$class [] Successfully started service 'SparkUI' on port 4040.
2020-01-06 18:26:49,505 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@61c11339{/jobs,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,506 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@54fbaa65{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,506 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@48e3017a{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,507 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@19877453{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,508 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@49bf5ec8{/stages,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,508 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@18174bd9{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,509 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@3af6d7a7{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,510 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@158cb50a{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,511 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@649a6d88{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,511 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@69e23e94{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,512 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@55c78556{/storage,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,513 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@25134e01{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,514 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@12d28106{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,514 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@6a3c1b56{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,515 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@3b8ce72{/environment,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,516 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@3ce4eb42{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,517 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@3a388769{/executors,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,517 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@3054cdd3{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,518 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@755a4ef5{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,519 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@6eff05e7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,525 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@1002c49e{/static,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,526 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@7bdaf563{/,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,527 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@53813f01{/api,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,529 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@1a4c6e74{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,530 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@28d728f1{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 18:26:49,533 INFO org.apache.spark.internal.Logging$class [] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 18:26:49,616 INFO org.apache.spark.internal.Logging$class [] Starting executor ID driver on host localhost
2020-01-06 18:26:49,646 INFO org.apache.spark.internal.Logging$class [] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62456.
2020-01-06 18:26:49,647 INFO org.apache.spark.internal.Logging$class [] Server created on DESKTOP-8VGF145.mshome.net:62456
2020-01-06 18:26:49,649 INFO org.apache.spark.internal.Logging$class [] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 18:26:49,684 INFO org.apache.spark.internal.Logging$class [] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 62456, None)
2020-01-06 18:26:49,688 INFO org.apache.spark.internal.Logging$class [] Registering block manager DESKTOP-8VGF145.mshome.net:62456 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 62456, None)
2020-01-06 18:26:49,694 INFO org.apache.spark.internal.Logging$class [] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 62456, None)
2020-01-06 18:26:49,695 INFO org.apache.spark.internal.Logging$class [] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 62456, None)
2020-01-06 18:26:49,716 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@3aac31b7{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 18:26:50,708 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2020-01-06 18:26:50,708 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Adding discovered server localhost:27017 to client view of cluster
2020-01-06 18:26:50,781 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Opened connection [connectionId{localValue:1, serverValue:13939}] to localhost:27017
2020-01-06 18:26:50,789 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 2, 1]}, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4659400}
2020-01-06 18:26:50,791 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Discovered cluster type of STANDALONE
2020-01-06 18:26:50,883 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:26:50,892 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:26:50,894 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:26:50,895 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:26:51,009 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:26:51,009 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:26:51,010 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:26:51,010 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:26:51,591 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Initializing ExecutorService 'applicationTaskExecutor'
2020-01-06 18:26:51,997 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Initializing ExecutorService 'taskScheduler'
2020-01-06 18:26:52,228 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel input
2020-01-06 18:26:52,355 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel output
2020-01-06 18:26:52,374 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel nullChannel
2020-01-06 18:26:52,402 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel errorChannel
2020-01-06 18:26:52,555 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageHandler errorLogger
2020-01-06 18:26:52,619 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.input' has 1 subscriber(s).
2020-01-06 18:26:52,627 INFO org.springframework.integration.endpoint.EventDrivenConsumer [] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 18:26:52,627 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.errorChannel' has 1 subscriber(s).
2020-01-06 18:26:52,627 INFO org.springframework.integration.endpoint.AbstractEndpoint [] started _org.springframework.integration.errorLogger
2020-01-06 18:26:52,916 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [] Attempting to connect to: [localhost:5672]
2020-01-06 18:26:53,018 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [] Created new connection: rabbitConnectionFactory#52bef30b:0/SimpleConnection@5b115d71 [delegate=amqp://guest@127.0.0.1:5672/, localPort= 62462]
2020-01-06 18:26:53,059 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.output' has 1 subscriber(s).
2020-01-06 18:26:53,089 INFO org.springframework.cloud.stream.binder.rabbit.provisioning.RabbitExchangeQueueProvisioner [] declaring queue for inbound: queue.log.messages.anonymous.7QJXrkZ8RP2oVflt7DP8RA, bound to: queue.log.messages
2020-01-06 18:26:53,113 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'unknown.channel.name' has 1 subscriber(s).
2020-01-06 18:26:53,114 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'unknown.channel.name' has 2 subscriber(s).
2020-01-06 18:26:53,136 INFO org.springframework.integration.endpoint.AbstractEndpoint [] started inbound.queue.log.messages.anonymous.7QJXrkZ8RP2oVflt7DP8RA
2020-01-06 18:26:53,158 INFO org.apache.juli.logging.DirectJDKLog [] Starting ProtocolHandler ["http-nio-8081"]
2020-01-06 18:26:53,177 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [] Tomcat started on port(s): 8081 (http) with context path ''
2020-01-06 18:26:53,180 INFO org.springframework.boot.StartupInfoLogger [] Started EventGeneratorApplication in 10.6772128 seconds (JVM running for 12.568)
2020-01-06 18:49:31,372 INFO org.springframework.boot.StartupInfoLogger [main] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 7460 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 18:49:31,374 INFO org.springframework.boot.SpringApplication [main] No active profile set, falling back to default profiles: default
2020-01-06 18:49:32,292 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 18:49:32,381 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Finished Spring Data repository scanning in 81ms. Found 2 repository interfaces.
2020-01-06 18:49:32,733 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [main] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 18:49:32,773 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 18:49:32,778 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 18:49:32,790 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 18:49:32,853 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:49:32,890 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$936022b5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:49:32,900 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$6ef22dd5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:49:32,909 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$a7d9d6a2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:49:32,917 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:49:33,297 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat initialized with port(s): 8081 (http)
2020-01-06 18:49:33,316 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 18:49:33,327 INFO org.apache.juli.logging.DirectJDKLog [main] Starting service [Tomcat]
2020-01-06 18:49:33,327 INFO org.apache.juli.logging.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 18:49:33,624 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2020-01-06 18:49:33,625 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 2163 ms
2020-01-06 18:49:36,191 INFO org.apache.spark.internal.Logging$class [main] Running Spark version 2.4.4
2020-01-06 18:49:36,325 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 18:49:36,406 INFO org.apache.spark.internal.Logging$class [main] Submitted application: test
2020-01-06 18:49:36,467 INFO org.apache.spark.internal.Logging$class [main] Changing view acls to: Marcos.Jaramillo
2020-01-06 18:49:36,469 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls to: Marcos.Jaramillo
2020-01-06 18:49:36,470 INFO org.apache.spark.internal.Logging$class [main] Changing view acls groups to: 
2020-01-06 18:49:36,471 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls groups to: 
2020-01-06 18:49:36,472 INFO org.apache.spark.internal.Logging$class [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 18:49:37,548 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'sparkDriver' on port 64716.
2020-01-06 18:49:37,566 INFO org.apache.spark.internal.Logging$class [main] Registering MapOutputTracker
2020-01-06 18:49:37,590 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManagerMaster
2020-01-06 18:49:37,593 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 18:49:37,593 INFO org.apache.spark.internal.Logging$class [main] BlockManagerMasterEndpoint up
2020-01-06 18:49:37,601 INFO org.apache.spark.internal.Logging$class [main] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-b68bf328-65b5-4345-912d-33bbd83e6844
2020-01-06 18:49:37,623 INFO org.apache.spark.internal.Logging$class [main] MemoryStore started with capacity 1992.0 MB
2020-01-06 18:49:37,639 INFO org.apache.spark.internal.Logging$class [main] Registering OutputCommitCoordinator
2020-01-06 18:49:37,709 INFO org.spark_project.jetty.util.log.Log [main] Logging initialized @8281ms
2020-01-06 18:49:37,762 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 18:49:37,776 INFO org.spark_project.jetty.server.Server [main] Started @8348ms
2020-01-06 18:49:37,801 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@14f254f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 18:49:37,801 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'SparkUI' on port 4040.
2020-01-06 18:49:37,818 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@24be6e34{/jobs,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,819 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1a23136f{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,819 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@23a78d2e{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,820 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@eb66b47{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,821 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@11e75942{/stages,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,821 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@23c61c1b{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,822 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4a6d6308{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,823 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7f5c4ff8{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,824 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7692c0e9{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,824 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@431f8830{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,825 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@75bbe39d{/storage,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,825 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6805415d{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,826 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@870413c{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,827 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3791160a{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,827 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1d9cac6e{/environment,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,828 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5f510929{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,829 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@55a2ca5e{/executors,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,829 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6abca7a6{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,830 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@12bb8943{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,832 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@45f4c27c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,838 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@64710a6{/static,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,839 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5f93ec02{/,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,840 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@57cc0333{/api,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,841 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2d732cda{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,841 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@755fdfad{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 18:49:37,844 INFO org.apache.spark.internal.Logging$class [main] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 18:49:37,929 INFO org.apache.spark.internal.Logging$class [main] Starting executor ID driver on host localhost
2020-01-06 18:49:37,957 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64733.
2020-01-06 18:49:37,959 INFO org.apache.spark.internal.Logging$class [main] Server created on DESKTOP-8VGF145.mshome.net:64733
2020-01-06 18:49:37,961 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 18:49:37,990 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 64733, None)
2020-01-06 18:49:37,994 INFO org.apache.spark.internal.Logging$class [] Registering block manager DESKTOP-8VGF145.mshome.net:64733 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 64733, None)
2020-01-06 18:49:38,000 INFO org.apache.spark.internal.Logging$class [main] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 64733, None)
2020-01-06 18:49:38,002 INFO org.apache.spark.internal.Logging$class [main] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 64733, None)
2020-01-06 18:49:38,023 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2c1b10f2{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:39,159 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2020-01-06 18:49:39,160 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Adding discovered server localhost:27017 to client view of cluster
2020-01-06 18:49:39,251 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Opened connection [connectionId{localValue:1, serverValue:13983}] to localhost:27017
2020-01-06 18:49:39,259 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 2, 1]}, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4736000}
2020-01-06 18:49:39,262 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Discovered cluster type of STANDALONE
2020-01-06 18:49:39,367 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:49:39,374 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:49:39,376 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:49:39,376 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:49:39,498 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:49:39,499 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:49:39,499 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:49:39,500 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:49:40,108 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'applicationTaskExecutor'
2020-01-06 18:49:40,493 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'taskScheduler'
2020-01-06 18:49:40,697 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel output
2020-01-06 18:49:40,857 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel nullChannel
2020-01-06 18:49:40,877 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel errorChannel
2020-01-06 18:49:40,942 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel input
2020-01-06 18:49:40,955 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageHandler errorLogger
2020-01-06 18:49:40,986 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.input' has 1 subscriber(s).
2020-01-06 18:49:40,990 INFO org.springframework.integration.endpoint.EventDrivenConsumer [main] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 18:49:40,990 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.errorChannel' has 1 subscriber(s).
2020-01-06 18:49:40,990 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started _org.springframework.integration.errorLogger
2020-01-06 18:49:41,204 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Attempting to connect to: [localhost:5672]
2020-01-06 18:49:41,241 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Created new connection: rabbitConnectionFactory#4f9871a2:0/SimpleConnection@7153995c [delegate=amqp://guest@127.0.0.1:5672/, localPort= 64736]
2020-01-06 18:49:41,272 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.output' has 1 subscriber(s).
2020-01-06 18:49:41,291 INFO org.springframework.cloud.stream.binder.rabbit.provisioning.RabbitExchangeQueueProvisioner [main] declaring queue for inbound: queue.log.messages.anonymous.vRqPvGKKQACtHiT2NpLDgw, bound to: queue.log.messages
2020-01-06 18:49:41,317 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 1 subscriber(s).
2020-01-06 18:49:41,317 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 2 subscriber(s).
2020-01-06 18:49:41,337 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started inbound.queue.log.messages.anonymous.vRqPvGKKQACtHiT2NpLDgw
2020-01-06 18:49:41,352 INFO org.apache.juli.logging.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-8081"]
2020-01-06 18:49:41,369 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat started on port(s): 8081 (http) with context path ''
2020-01-06 18:49:41,371 INFO org.springframework.boot.StartupInfoLogger [main] Started EventGeneratorApplication in 10.5825968 seconds (JVM running for 11.943)
2020-01-06 18:49:52,075 INFO com.ternium.core.eventgenerator.stream.RabbitStream [] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:49:52,076 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [] Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:49:52,085 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [] Attempting to connect to: [localhost:5672]
2020-01-06 18:49:52,092 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [] Created new connection: rabbitConnectionFactory.publisher#4772e7e8:0/SimpleConnection@3b5d7491 [delegate=amqp://guest@127.0.0.1:5672/, localPort= 64807]
2020-01-06 18:49:52,092 INFO org.springframework.amqp.rabbit.core.RabbitAdmin [] Auto-declaring a non-durable, auto-delete, or exclusive Queue (queue.log.messages.anonymous.vRqPvGKKQACtHiT2NpLDgw) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost.
2020-01-06 18:49:52,149 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [84] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:49:52,151 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [84] SPARK Context Builded
2020-01-06 18:49:52,151 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [84] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 18:49:53,837 INFO org.apache.spark.internal.Logging$class [84] Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/Proyectos/Translados/GitHub/mine/EventGenerator/EventGenerator/spark-warehouse').
2020-01-06 18:49:53,838 INFO org.apache.spark.internal.Logging$class [84] Warehouse path is 'file:/D:/Proyectos/Translados/GitHub/mine/EventGenerator/EventGenerator/spark-warehouse'.
2020-01-06 18:49:53,848 INFO org.spark_project.jetty.server.handler.ContextHandler [84] Started o.s.j.s.ServletContextHandler@7d686511{/SQL,null,AVAILABLE,@Spark}
2020-01-06 18:49:53,849 INFO org.spark_project.jetty.server.handler.ContextHandler [84] Started o.s.j.s.ServletContextHandler@12d8d713{/SQL/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:53,850 INFO org.spark_project.jetty.server.handler.ContextHandler [84] Started o.s.j.s.ServletContextHandler@662c43f4{/SQL/execution,null,AVAILABLE,@Spark}
2020-01-06 18:49:53,851 INFO org.spark_project.jetty.server.handler.ContextHandler [84] Started o.s.j.s.ServletContextHandler@5d8f87c7{/SQL/execution/json,null,AVAILABLE,@Spark}
2020-01-06 18:49:53,852 INFO org.spark_project.jetty.server.handler.ContextHandler [84] Started o.s.j.s.ServletContextHandler@354f8a64{/static/sql,null,AVAILABLE,@Spark}
2020-01-06 18:49:54,159 INFO org.apache.spark.internal.Logging$class [84] Registered StateStoreCoordinator endpoint
2020-01-06 18:49:54,417 INFO org.apache.spark.internal.Logging$class [84] Code generated in 204.357 ms
2020-01-06 18:49:54,972 INFO org.apache.spark.internal.Logging$class [84] Code generated in 12.4191 ms
2020-01-06 18:49:54,991 INFO org.apache.spark.internal.Logging$class [84] Code generated in 10.4421 ms
2020-01-06 18:49:55,017 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [84] data:=[value: string]
2020-01-06 18:49:55,019 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] Going to call the group FilterRules
2020-01-06 18:49:55,130 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:49:55,131 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [84] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 18:49:55,132 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] Going to call the group Translator
2020-01-06 18:49:55,159 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 18:49:55,160 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] Going to call the group Transformation
2020-01-06 18:49:55,190 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 18:49:55,277 INFO com.mongodb.diagnostics.logging.SLF4JLogger [84] Opened connection [connectionId{localValue:2, serverValue:13985}] to localhost:27017
2020-01-06 18:49:55,322 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [84] Data Already Exist
2020-01-06 18:49:55,325 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [84] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:42)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 18:50:22,164 INFO org.apache.spark.internal.Logging$class [] Cleaned accumulator 0
2020-01-06 18:57:43,492 INFO org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin [] Application shutdown requested.
2020-01-06 18:57:44,150 INFO org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer [] Waiting for workers to finish.
2020-01-06 18:57:44,463 INFO org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer [] Successfully waited for workers to finish.
2020-01-06 18:57:44,463 INFO org.springframework.integration.endpoint.AbstractEndpoint [] stopped inbound.queue.log.messages.anonymous.vRqPvGKKQACtHiT2NpLDgw
2020-01-06 18:57:44,477 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel queue.log.messages.anonymous.vRqPvGKKQACtHiT2NpLDgw.errors
2020-01-06 18:57:44,624 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.queue.log.messages.anonymous.vRqPvGKKQACtHiT2NpLDgw.errors' has 1 subscriber(s).
2020-01-06 18:57:44,625 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.queue.log.messages.anonymous.vRqPvGKKQACtHiT2NpLDgw.errors' has 0 subscriber(s).
2020-01-06 18:57:44,629 INFO org.springframework.integration.endpoint.EventDrivenConsumer [] Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 18:57:44,630 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.errorChannel' has 0 subscriber(s).
2020-01-06 18:57:44,630 INFO org.springframework.integration.endpoint.AbstractEndpoint [] stopped _org.springframework.integration.errorLogger
2020-01-06 18:57:44,631 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Shutting down ExecutorService 'taskScheduler'
2020-01-06 18:57:44,646 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Shutting down ExecutorService 'applicationTaskExecutor'
2020-01-06 18:57:44,653 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Closed connection [connectionId{localValue:2, serverValue:13985}] to localhost:27017 because the pool has been closed.
2020-01-06 18:57:44,668 INFO org.spark_project.jetty.server.AbstractConnector [] Stopped Spark@14f254f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 18:57:44,670 INFO org.apache.spark.internal.Logging$class [] Stopped Spark web UI at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 18:57:44,689 INFO org.apache.spark.internal.Logging$class [] MapOutputTrackerMasterEndpoint stopped!
2020-01-06 18:57:44,701 INFO org.apache.spark.internal.Logging$class [] MemoryStore cleared
2020-01-06 18:57:44,702 INFO org.apache.spark.internal.Logging$class [] BlockManager stopped
2020-01-06 18:57:44,703 INFO org.apache.spark.internal.Logging$class [] BlockManagerMaster stopped
2020-01-06 18:57:44,708 INFO org.apache.spark.internal.Logging$class [] OutputCommitCoordinator stopped!
2020-01-06 18:57:44,714 INFO org.apache.spark.internal.Logging$class [] Successfully stopped SparkContext
2020-01-06 18:57:44,715 INFO org.apache.spark.internal.Logging$class [] SparkContext already stopped.
2020-01-06 18:57:44,717 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: output
2020-01-06 18:57:44,717 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: nullChannel
2020-01-06 18:57:44,717 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: errorChannel
2020-01-06 18:57:44,718 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: input
2020-01-06 18:57:44,718 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: _org.springframework.integration.errorLogger.handler
2020-01-06 18:57:44,987 INFO org.apache.spark.internal.Logging$class [] Shutdown hook called
2020-01-06 18:57:45,057 INFO org.apache.spark.internal.Logging$class [] Deleting directory C:\Users\Marcos.Jaramillo\AppData\Local\Temp\spark-661e280e-5503-4a51-9945-b1d44ef10921
2020-01-06 18:57:53,967 INFO org.springframework.boot.StartupInfoLogger [main] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 18568 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 18:57:53,971 INFO org.springframework.boot.SpringApplication [main] No active profile set, falling back to default profiles: default
2020-01-06 18:57:55,149 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 18:57:55,258 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Finished Spring Data repository scanning in 102ms. Found 2 repository interfaces.
2020-01-06 18:57:55,683 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [main] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 18:57:55,719 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 18:57:55,725 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 18:57:55,738 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 18:57:55,801 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:57:55,843 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$e992b852] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:57:55,853 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$c524c372] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:57:55,861 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$fe0c6c3f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:57:55,867 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:57:56,190 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat initialized with port(s): 8081 (http)
2020-01-06 18:57:56,209 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 18:57:56,218 INFO org.apache.juli.logging.DirectJDKLog [main] Starting service [Tomcat]
2020-01-06 18:57:56,218 INFO org.apache.juli.logging.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 18:57:56,487 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2020-01-06 18:57:56,487 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 2357 ms
2020-01-06 18:57:59,145 INFO org.apache.spark.internal.Logging$class [main] Running Spark version 2.4.4
2020-01-06 18:57:59,281 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 18:57:59,362 INFO org.apache.spark.internal.Logging$class [main] Submitted application: test
2020-01-06 18:57:59,415 INFO org.apache.spark.internal.Logging$class [main] Changing view acls to: Marcos.Jaramillo
2020-01-06 18:57:59,416 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls to: Marcos.Jaramillo
2020-01-06 18:57:59,418 INFO org.apache.spark.internal.Logging$class [main] Changing view acls groups to: 
2020-01-06 18:57:59,419 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls groups to: 
2020-01-06 18:57:59,420 INFO org.apache.spark.internal.Logging$class [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 18:58:00,617 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'sparkDriver' on port 49191.
2020-01-06 18:58:00,640 INFO org.apache.spark.internal.Logging$class [main] Registering MapOutputTracker
2020-01-06 18:58:00,666 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManagerMaster
2020-01-06 18:58:00,669 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 18:58:00,670 INFO org.apache.spark.internal.Logging$class [main] BlockManagerMasterEndpoint up
2020-01-06 18:58:00,678 INFO org.apache.spark.internal.Logging$class [main] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-a5b325ad-75eb-49f0-afdf-1cc2bb5da1e1
2020-01-06 18:58:00,706 INFO org.apache.spark.internal.Logging$class [main] MemoryStore started with capacity 1992.0 MB
2020-01-06 18:58:00,726 INFO org.apache.spark.internal.Logging$class [main] Registering OutputCommitCoordinator
2020-01-06 18:58:00,825 INFO org.spark_project.jetty.util.log.Log [main] Logging initialized @9390ms
2020-01-06 18:58:00,888 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 18:58:00,904 INFO org.spark_project.jetty.server.Server [main] Started @9470ms
2020-01-06 18:58:00,929 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@16b713dd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 18:58:00,930 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'SparkUI' on port 4040.
2020-01-06 18:58:00,955 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@31d8352e{/jobs,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,956 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7bbc11ed{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,957 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7d741200{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,958 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6af02de0{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,959 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3749c6ac{/stages,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,959 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@9cdf13e{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,960 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3bede349{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,961 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@129b0ed{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,962 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4ccf1d3e{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,962 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@75ff2b6d{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,963 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@20a7ce0{/storage,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,963 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4ee80a94{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,964 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7afac89a{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,965 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@76d220eb{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,967 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@276eafad{/environment,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,968 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@29dcad7e{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,968 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5ce1ec7{/executors,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,969 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@627cb3ed{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,969 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@30bd6bc8{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,970 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7c4697fc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,975 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@90b9695{/static,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,976 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@23243bc0{/,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,978 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@770c3ca2{/api,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,979 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@659565ed{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,979 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@481eb705{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 18:58:00,982 INFO org.apache.spark.internal.Logging$class [main] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 18:58:01,069 INFO org.apache.spark.internal.Logging$class [main] Starting executor ID driver on host localhost
2020-01-06 18:58:01,103 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49208.
2020-01-06 18:58:01,105 INFO org.apache.spark.internal.Logging$class [main] Server created on DESKTOP-8VGF145.mshome.net:49208
2020-01-06 18:58:01,107 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 18:58:01,140 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49208, None)
2020-01-06 18:58:01,146 INFO org.apache.spark.internal.Logging$class [] Registering block manager DESKTOP-8VGF145.mshome.net:49208 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49208, None)
2020-01-06 18:58:01,152 INFO org.apache.spark.internal.Logging$class [main] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49208, None)
2020-01-06 18:58:01,153 INFO org.apache.spark.internal.Logging$class [main] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49208, None)
2020-01-06 18:58:01,172 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@16422f27{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 18:58:02,315 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2020-01-06 18:58:02,316 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Adding discovered server localhost:27017 to client view of cluster
2020-01-06 18:58:02,392 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Opened connection [connectionId{localValue:1, serverValue:14001}] to localhost:27017
2020-01-06 18:58:02,401 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 2, 1]}, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=5312700}
2020-01-06 18:58:02,403 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Discovered cluster type of STANDALONE
2020-01-06 18:58:02,495 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:58:02,501 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:58:02,503 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:58:02,504 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:58:02,619 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:58:02,620 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:58:02,621 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:58:02,621 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 18:58:03,335 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'applicationTaskExecutor'
2020-01-06 18:58:03,758 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'taskScheduler'
2020-01-06 18:58:04,006 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel output
2020-01-06 18:58:04,102 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel nullChannel
2020-01-06 18:58:04,121 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel errorChannel
2020-01-06 18:58:04,176 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel input
2020-01-06 18:58:04,186 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageHandler errorLogger
2020-01-06 18:58:04,221 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.input' has 1 subscriber(s).
2020-01-06 18:58:04,226 INFO org.springframework.integration.endpoint.EventDrivenConsumer [main] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 18:58:04,226 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.errorChannel' has 1 subscriber(s).
2020-01-06 18:58:04,227 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started _org.springframework.integration.errorLogger
2020-01-06 18:58:04,440 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Attempting to connect to: [localhost:5672]
2020-01-06 18:58:04,477 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Created new connection: rabbitConnectionFactory#7aafac17:0/SimpleConnection@46c6541f [delegate=amqp://guest@127.0.0.1:5672/, localPort= 49212]
2020-01-06 18:58:04,512 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.output' has 1 subscriber(s).
2020-01-06 18:58:04,535 INFO org.springframework.cloud.stream.binder.rabbit.provisioning.RabbitExchangeQueueProvisioner [main] declaring queue for inbound: queue.log.messages.anonymous.xkrpWzK3QbuR2gOx4zSdIw, bound to: queue.log.messages
2020-01-06 18:58:04,559 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 1 subscriber(s).
2020-01-06 18:58:04,559 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 2 subscriber(s).
2020-01-06 18:58:04,583 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started inbound.queue.log.messages.anonymous.xkrpWzK3QbuR2gOx4zSdIw
2020-01-06 18:58:04,597 INFO org.apache.juli.logging.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-8081"]
2020-01-06 18:58:04,617 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat started on port(s): 8081 (http) with context path ''
2020-01-06 18:58:04,619 INFO org.springframework.boot.StartupInfoLogger [main] Started EventGeneratorApplication in 11.7458729 seconds (JVM running for 13.184)
2020-01-06 18:59:41,078 INFO org.springframework.boot.StartupInfoLogger [main] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 27456 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 18:59:41,080 INFO org.springframework.boot.SpringApplication [main] No active profile set, falling back to default profiles: default
2020-01-06 18:59:41,783 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 18:59:41,860 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Finished Spring Data repository scanning in 70ms. Found 2 repository interfaces.
2020-01-06 18:59:42,217 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [main] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 18:59:42,256 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 18:59:42,261 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 18:59:42,274 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 18:59:42,335 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:59:42,367 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$991fc753] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:59:42,375 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$74b1d273] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:59:42,384 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$ad997b40] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:59:42,390 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 18:59:42,727 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat initialized with port(s): 8081 (http)
2020-01-06 18:59:42,742 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 18:59:42,752 INFO org.apache.juli.logging.DirectJDKLog [main] Starting service [Tomcat]
2020-01-06 18:59:42,752 INFO org.apache.juli.logging.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 18:59:43,129 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2020-01-06 18:59:43,129 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 1970 ms
2020-01-06 18:59:45,963 INFO org.apache.spark.internal.Logging$class [main] Running Spark version 2.4.4
2020-01-06 18:59:46,109 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 18:59:46,189 INFO org.apache.spark.internal.Logging$class [main] Submitted application: test
2020-01-06 18:59:46,251 INFO org.apache.spark.internal.Logging$class [main] Changing view acls to: Marcos.Jaramillo
2020-01-06 18:59:46,252 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls to: Marcos.Jaramillo
2020-01-06 18:59:46,252 INFO org.apache.spark.internal.Logging$class [main] Changing view acls groups to: 
2020-01-06 18:59:46,253 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls groups to: 
2020-01-06 18:59:46,254 INFO org.apache.spark.internal.Logging$class [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 18:59:47,345 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'sparkDriver' on port 49387.
2020-01-06 18:59:47,365 INFO org.apache.spark.internal.Logging$class [main] Registering MapOutputTracker
2020-01-06 18:59:47,388 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManagerMaster
2020-01-06 18:59:47,391 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 18:59:47,391 INFO org.apache.spark.internal.Logging$class [main] BlockManagerMasterEndpoint up
2020-01-06 18:59:47,398 INFO org.apache.spark.internal.Logging$class [main] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-2727b6c4-613e-40e5-9f12-ae867e48f900
2020-01-06 18:59:47,427 INFO org.apache.spark.internal.Logging$class [main] MemoryStore started with capacity 1992.0 MB
2020-01-06 18:59:47,447 INFO org.apache.spark.internal.Logging$class [main] Registering OutputCommitCoordinator
2020-01-06 18:59:47,508 INFO org.spark_project.jetty.util.log.Log [main] Logging initialized @8304ms
2020-01-06 18:59:47,568 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 18:59:47,583 INFO org.spark_project.jetty.server.Server [main] Started @8379ms
2020-01-06 18:59:47,598 WARN org.apache.spark.internal.Logging$class [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2020-01-06 18:59:47,607 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@738153d8{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2020-01-06 18:59:47,607 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'SparkUI' on port 4041.
2020-01-06 18:59:47,625 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@34766f4b{/jobs,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,625 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1fa77770{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,626 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@62f3ad90{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,627 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4a532271{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,627 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@35b38986{/stages,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,628 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1c000c2f{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,628 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2c7ac998{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,629 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6e7d9d0{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,630 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2b0d818d{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,631 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7212b28e{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,632 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@306c8e09{/storage,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,633 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@87df88d{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,633 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4f3b11e6{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,634 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@28da5c4d{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,634 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7c928399{/environment,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,635 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1bcca516{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,636 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@cef23a8{/executors,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,636 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@762d2e4c{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,637 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1e4bf55b{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,638 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@60510791{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,642 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@15d68a50{/static,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,643 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4246f904{/,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,644 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5b01b3f8{/api,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,645 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4a5c6b30{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,645 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@49616310{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 18:59:47,648 INFO org.apache.spark.internal.Logging$class [main] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4041
2020-01-06 18:59:47,742 INFO org.apache.spark.internal.Logging$class [main] Starting executor ID driver on host localhost
2020-01-06 18:59:47,784 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49404.
2020-01-06 18:59:47,785 INFO org.apache.spark.internal.Logging$class [main] Server created on DESKTOP-8VGF145.mshome.net:49404
2020-01-06 18:59:47,787 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 18:59:47,814 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49404, None)
2020-01-06 18:59:47,818 INFO org.apache.spark.internal.Logging$class [] Registering block manager DESKTOP-8VGF145.mshome.net:49404 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49404, None)
2020-01-06 18:59:47,823 INFO org.apache.spark.internal.Logging$class [main] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49404, None)
2020-01-06 18:59:47,823 INFO org.apache.spark.internal.Logging$class [main] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49404, None)
2020-01-06 18:59:47,838 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@9cdf13e{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:27,938 INFO org.springframework.boot.StartupInfoLogger [main] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 36844 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 19:00:27,978 INFO org.springframework.boot.SpringApplication [main] No active profile set, falling back to default profiles: default
2020-01-06 19:00:28,656 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 19:00:28,737 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Finished Spring Data repository scanning in 76ms. Found 2 repository interfaces.
2020-01-06 19:00:29,044 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [main] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 19:00:29,077 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 19:00:29,083 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 19:00:29,092 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 19:00:29,148 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:00:29,185 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$66e5a61f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:00:29,195 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$4277b13f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:00:29,205 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$7b5f5a0c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:00:29,210 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:00:29,517 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat initialized with port(s): 8081 (http)
2020-01-06 19:00:29,532 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 19:00:29,544 INFO org.apache.juli.logging.DirectJDKLog [main] Starting service [Tomcat]
2020-01-06 19:00:29,545 INFO org.apache.juli.logging.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 19:00:29,829 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2020-01-06 19:00:29,829 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 1802 ms
2020-01-06 19:00:32,403 INFO org.apache.spark.internal.Logging$class [main] Running Spark version 2.4.4
2020-01-06 19:00:32,560 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 19:00:32,641 INFO org.apache.spark.internal.Logging$class [main] Submitted application: test
2020-01-06 19:00:32,697 INFO org.apache.spark.internal.Logging$class [main] Changing view acls to: Marcos.Jaramillo
2020-01-06 19:00:32,698 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls to: Marcos.Jaramillo
2020-01-06 19:00:32,700 INFO org.apache.spark.internal.Logging$class [main] Changing view acls groups to: 
2020-01-06 19:00:32,700 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls groups to: 
2020-01-06 19:00:32,701 INFO org.apache.spark.internal.Logging$class [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 19:00:33,835 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'sparkDriver' on port 49521.
2020-01-06 19:00:33,853 INFO org.apache.spark.internal.Logging$class [main] Registering MapOutputTracker
2020-01-06 19:00:33,876 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManagerMaster
2020-01-06 19:00:33,879 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 19:00:33,880 INFO org.apache.spark.internal.Logging$class [main] BlockManagerMasterEndpoint up
2020-01-06 19:00:33,888 INFO org.apache.spark.internal.Logging$class [main] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-15ac2ce2-f6ba-44be-bc25-17eef4edb784
2020-01-06 19:00:33,913 INFO org.apache.spark.internal.Logging$class [main] MemoryStore started with capacity 1992.0 MB
2020-01-06 19:00:33,932 INFO org.apache.spark.internal.Logging$class [main] Registering OutputCommitCoordinator
2020-01-06 19:00:33,995 INFO org.spark_project.jetty.util.log.Log [main] Logging initialized @8027ms
2020-01-06 19:00:34,054 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 19:00:34,068 INFO org.spark_project.jetty.server.Server [main] Started @8100ms
2020-01-06 19:00:34,091 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@673e1cf2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 19:00:34,092 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'SparkUI' on port 4040.
2020-01-06 19:00:34,109 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4446a191{/jobs,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,110 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2e7563f6{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,110 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@72fa021{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,111 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7e864fa4{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,111 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@452d6fd{/stages,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,112 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@38dc1c50{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,112 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@ccea4be{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,113 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7a05cdc8{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,114 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5f3fafca{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,115 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@174aabb2{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,116 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@33b4c775{/storage,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,117 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@678b3746{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,117 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@45689582{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,118 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@73db1a6{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,119 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@12a7515b{/environment,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,120 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2c28654e{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,121 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2ded31cc{/executors,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,122 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@47b71556{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,123 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6fb2b972{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,123 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5fa3df{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,128 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@44f88149{/static,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,129 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3fae357f{/,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,130 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@50bc0bbd{/api,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,130 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@230e163b{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,131 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7a41f4a7{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 19:00:34,134 INFO org.apache.spark.internal.Logging$class [main] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 19:00:34,235 INFO org.apache.spark.internal.Logging$class [main] Starting executor ID driver on host localhost
2020-01-06 19:00:34,268 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49538.
2020-01-06 19:00:34,270 INFO org.apache.spark.internal.Logging$class [main] Server created on DESKTOP-8VGF145.mshome.net:49538
2020-01-06 19:00:34,271 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 19:00:34,299 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49538, None)
2020-01-06 19:00:34,303 INFO org.apache.spark.internal.Logging$class [] Registering block manager DESKTOP-8VGF145.mshome.net:49538 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49538, None)
2020-01-06 19:00:34,307 INFO org.apache.spark.internal.Logging$class [main] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49538, None)
2020-01-06 19:00:34,308 INFO org.apache.spark.internal.Logging$class [main] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49538, None)
2020-01-06 19:00:34,323 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3b235623{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 19:00:35,310 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2020-01-06 19:00:35,310 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Adding discovered server localhost:27017 to client view of cluster
2020-01-06 19:00:35,386 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Opened connection [connectionId{localValue:1, serverValue:14007}] to localhost:27017
2020-01-06 19:00:35,393 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 2, 1]}, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4903000}
2020-01-06 19:00:35,395 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Discovered cluster type of STANDALONE
2020-01-06 19:00:35,498 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:00:35,507 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:00:35,508 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:00:35,509 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:00:35,614 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:00:35,615 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:00:35,616 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:00:35,616 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:00:36,172 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'applicationTaskExecutor'
2020-01-06 19:00:36,612 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'taskScheduler'
2020-01-06 19:00:36,825 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel nullChannel
2020-01-06 19:00:36,846 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel errorChannel
2020-01-06 19:00:36,978 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel input
2020-01-06 19:00:37,026 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel output
2020-01-06 19:00:37,038 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageHandler errorLogger
2020-01-06 19:00:37,069 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.input' has 1 subscriber(s).
2020-01-06 19:00:37,073 INFO org.springframework.integration.endpoint.EventDrivenConsumer [main] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 19:00:37,074 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.errorChannel' has 1 subscriber(s).
2020-01-06 19:00:37,074 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started _org.springframework.integration.errorLogger
2020-01-06 19:00:37,291 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Attempting to connect to: [localhost:5672]
2020-01-06 19:00:37,327 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Created new connection: rabbitConnectionFactory#749054a3:0/SimpleConnection@274de4bc [delegate=amqp://guest@127.0.0.1:5672/, localPort= 49544]
2020-01-06 19:00:37,359 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.output' has 1 subscriber(s).
2020-01-06 19:00:37,384 INFO org.springframework.cloud.stream.binder.rabbit.provisioning.RabbitExchangeQueueProvisioner [main] declaring queue for inbound: queue.log.messages.anonymous.VmEZ4rYWQd60uM-4V2zv3g, bound to: queue.log.messages
2020-01-06 19:00:37,405 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 1 subscriber(s).
2020-01-06 19:00:37,406 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 2 subscriber(s).
2020-01-06 19:00:37,427 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started inbound.queue.log.messages.anonymous.VmEZ4rYWQd60uM-4V2zv3g
2020-01-06 19:00:37,440 INFO org.apache.juli.logging.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-8081"]
2020-01-06 19:00:37,456 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat started on port(s): 8081 (http) with context path ''
2020-01-06 19:00:37,459 INFO org.springframework.boot.StartupInfoLogger [main] Started EventGeneratorApplication in 10.0835967 seconds (JVM running for 11.49)
2020-01-06 19:01:18,163 INFO org.springframework.boot.StartupInfoLogger [main] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 30236 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 19:01:18,165 INFO org.springframework.boot.SpringApplication [main] No active profile set, falling back to default profiles: default
2020-01-06 19:01:18,888 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 19:01:18,978 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Finished Spring Data repository scanning in 84ms. Found 2 repository interfaces.
2020-01-06 19:01:19,339 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [main] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 19:01:19,383 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 19:01:19,391 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 19:01:19,404 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 19:01:19,455 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:01:19,480 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$84a3874b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:01:19,487 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$6035926b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:01:19,496 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$991d3b38] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:01:19,502 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:01:19,805 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat initialized with port(s): 8081 (http)
2020-01-06 19:01:19,822 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 19:01:19,843 INFO org.apache.juli.logging.DirectJDKLog [main] Starting service [Tomcat]
2020-01-06 19:01:19,844 INFO org.apache.juli.logging.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 19:01:20,140 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2020-01-06 19:01:20,140 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 1922 ms
2020-01-06 19:01:22,918 INFO org.apache.spark.internal.Logging$class [main] Running Spark version 2.4.4
2020-01-06 19:01:23,166 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 19:01:23,307 INFO org.apache.spark.internal.Logging$class [main] Submitted application: test
2020-01-06 19:01:23,363 INFO org.apache.spark.internal.Logging$class [main] Changing view acls to: Marcos.Jaramillo
2020-01-06 19:01:23,365 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls to: Marcos.Jaramillo
2020-01-06 19:01:23,366 INFO org.apache.spark.internal.Logging$class [main] Changing view acls groups to: 
2020-01-06 19:01:23,368 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls groups to: 
2020-01-06 19:01:23,368 INFO org.apache.spark.internal.Logging$class [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 19:01:24,431 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'sparkDriver' on port 49662.
2020-01-06 19:01:24,448 INFO org.apache.spark.internal.Logging$class [main] Registering MapOutputTracker
2020-01-06 19:01:24,472 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManagerMaster
2020-01-06 19:01:24,474 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 19:01:24,475 INFO org.apache.spark.internal.Logging$class [main] BlockManagerMasterEndpoint up
2020-01-06 19:01:24,481 INFO org.apache.spark.internal.Logging$class [main] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-094aec75-f6ff-4bb6-957f-f48ba5c12c8d
2020-01-06 19:01:24,507 INFO org.apache.spark.internal.Logging$class [main] MemoryStore started with capacity 1992.0 MB
2020-01-06 19:01:24,526 INFO org.apache.spark.internal.Logging$class [main] Registering OutputCommitCoordinator
2020-01-06 19:01:24,591 INFO org.spark_project.jetty.util.log.Log [main] Logging initialized @8345ms
2020-01-06 19:01:24,646 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 19:01:24,660 INFO org.spark_project.jetty.server.Server [main] Started @8414ms
2020-01-06 19:01:24,681 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@659565ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 19:01:24,682 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'SparkUI' on port 4040.
2020-01-06 19:01:24,705 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@213c812a{/jobs,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,706 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@94b5fe3{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,707 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4417755b{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,707 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@c6db00d{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,708 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@732fa176{/stages,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,709 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@413e8246{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,709 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4c7b4a31{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,710 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@162a5c4c{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,711 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5f0bf0ed{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,711 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6f9e6a85{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,712 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2e17a9e6{/storage,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,712 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6a1b4854{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,713 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6a175162{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,713 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7641c4e7{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,714 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@650a0b50{/environment,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,715 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@55e3b64d{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,716 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@52f71d2{/executors,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,717 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7d31fb6c{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,718 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@48543f11{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,718 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@cda988{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,723 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7e92e9a2{/static,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,723 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5e97da56{/,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,725 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6e8f3b76{/api,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,725 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@28721794{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,726 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3507200d{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 19:01:24,728 INFO org.apache.spark.internal.Logging$class [main] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 19:01:24,800 INFO org.apache.spark.internal.Logging$class [main] Starting executor ID driver on host localhost
2020-01-06 19:01:24,835 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49688.
2020-01-06 19:01:24,836 INFO org.apache.spark.internal.Logging$class [main] Server created on DESKTOP-8VGF145.mshome.net:49688
2020-01-06 19:01:24,838 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 19:01:24,865 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49688, None)
2020-01-06 19:01:24,869 INFO org.apache.spark.internal.Logging$class [] Registering block manager DESKTOP-8VGF145.mshome.net:49688 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49688, None)
2020-01-06 19:01:24,873 INFO org.apache.spark.internal.Logging$class [main] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49688, None)
2020-01-06 19:01:24,874 INFO org.apache.spark.internal.Logging$class [main] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49688, None)
2020-01-06 19:01:24,889 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2c3f81ef{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 19:01:26,041 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2020-01-06 19:01:26,042 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Adding discovered server localhost:27017 to client view of cluster
2020-01-06 19:01:26,135 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Opened connection [connectionId{localValue:1, serverValue:14009}] to localhost:27017
2020-01-06 19:01:26,142 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 2, 1]}, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4600000}
2020-01-06 19:01:26,144 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Discovered cluster type of STANDALONE
2020-01-06 19:01:26,269 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:01:26,277 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:01:26,279 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:01:26,280 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:01:26,408 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:01:26,409 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:01:26,410 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:01:26,411 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:01:27,128 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'applicationTaskExecutor'
2020-01-06 19:01:27,675 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'taskScheduler'
2020-01-06 19:01:27,979 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel output
2020-01-06 19:01:28,145 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel nullChannel
2020-01-06 19:01:28,174 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel errorChannel
2020-01-06 19:01:28,243 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel input
2020-01-06 19:01:28,256 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageHandler errorLogger
2020-01-06 19:01:28,301 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.input' has 1 subscriber(s).
2020-01-06 19:01:28,307 INFO org.springframework.integration.endpoint.EventDrivenConsumer [main] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 19:01:28,307 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.errorChannel' has 1 subscriber(s).
2020-01-06 19:01:28,307 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started _org.springframework.integration.errorLogger
2020-01-06 19:01:28,621 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Attempting to connect to: [localhost:5672]
2020-01-06 19:01:28,661 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Created new connection: rabbitConnectionFactory#4398d:0/SimpleConnection@4bd1541f [delegate=amqp://guest@127.0.0.1:5672/, localPort= 49698]
2020-01-06 19:01:28,703 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.output' has 1 subscriber(s).
2020-01-06 19:01:28,730 INFO org.springframework.cloud.stream.binder.rabbit.provisioning.RabbitExchangeQueueProvisioner [main] declaring queue for inbound: queue.log.messages.anonymous.hsVUu5wCRD6iqxTjQ0gFSw, bound to: queue.log.messages
2020-01-06 19:01:28,759 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 1 subscriber(s).
2020-01-06 19:01:28,760 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 2 subscriber(s).
2020-01-06 19:01:28,783 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started inbound.queue.log.messages.anonymous.hsVUu5wCRD6iqxTjQ0gFSw
2020-01-06 19:01:28,803 INFO org.apache.juli.logging.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-8081"]
2020-01-06 19:01:28,823 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat started on port(s): 8081 (http) with context path ''
2020-01-06 19:01:28,825 INFO org.springframework.boot.StartupInfoLogger [main] Started EventGeneratorApplication in 11.2166725 seconds (JVM running for 12.579)
2020-01-06 19:01:33,528 INFO org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin [] Application shutdown requested.
2020-01-06 19:01:33,563 INFO org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer [] Waiting for workers to finish.
2020-01-06 19:01:33,795 INFO org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer [] Successfully waited for workers to finish.
2020-01-06 19:01:33,795 INFO org.springframework.integration.endpoint.AbstractEndpoint [] stopped inbound.queue.log.messages.anonymous.hsVUu5wCRD6iqxTjQ0gFSw
2020-01-06 19:01:33,811 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel queue.log.messages.anonymous.hsVUu5wCRD6iqxTjQ0gFSw.errors
2020-01-06 19:01:34,000 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.queue.log.messages.anonymous.hsVUu5wCRD6iqxTjQ0gFSw.errors' has 1 subscriber(s).
2020-01-06 19:01:34,002 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.queue.log.messages.anonymous.hsVUu5wCRD6iqxTjQ0gFSw.errors' has 0 subscriber(s).
2020-01-06 19:01:34,007 INFO org.springframework.integration.endpoint.EventDrivenConsumer [] Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 19:01:34,008 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.errorChannel' has 0 subscriber(s).
2020-01-06 19:01:34,008 INFO org.springframework.integration.endpoint.AbstractEndpoint [] stopped _org.springframework.integration.errorLogger
2020-01-06 19:01:34,009 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Shutting down ExecutorService 'taskScheduler'
2020-01-06 19:01:34,019 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Shutting down ExecutorService 'applicationTaskExecutor'
2020-01-06 19:01:34,035 INFO org.spark_project.jetty.server.AbstractConnector [] Stopped Spark@659565ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 19:01:34,038 INFO org.apache.spark.internal.Logging$class [] Stopped Spark web UI at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 19:01:34,057 INFO org.apache.spark.internal.Logging$class [] MapOutputTrackerMasterEndpoint stopped!
2020-01-06 19:01:34,069 INFO org.apache.spark.internal.Logging$class [] MemoryStore cleared
2020-01-06 19:01:34,071 INFO org.apache.spark.internal.Logging$class [] BlockManager stopped
2020-01-06 19:01:34,079 INFO org.apache.spark.internal.Logging$class [] BlockManagerMaster stopped
2020-01-06 19:01:34,086 INFO org.apache.spark.internal.Logging$class [] OutputCommitCoordinator stopped!
2020-01-06 19:01:34,092 INFO org.apache.spark.internal.Logging$class [] Successfully stopped SparkContext
2020-01-06 19:01:34,094 INFO org.apache.spark.internal.Logging$class [] SparkContext already stopped.
2020-01-06 19:01:34,095 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: output
2020-01-06 19:01:34,095 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: nullChannel
2020-01-06 19:01:34,096 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: errorChannel
2020-01-06 19:01:34,096 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: input
2020-01-06 19:01:34,096 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: _org.springframework.integration.errorLogger.handler
2020-01-06 19:01:34,639 INFO org.apache.spark.internal.Logging$class [] Shutdown hook called
2020-01-06 19:01:34,640 INFO org.apache.spark.internal.Logging$class [] Deleting directory C:\Users\Marcos.Jaramillo\AppData\Local\Temp\spark-33c460be-172a-416f-91f4-73cdd5b21eee
2020-01-06 19:02:42,835 INFO org.springframework.boot.StartupInfoLogger [main] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 33556 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 19:02:42,837 INFO org.springframework.boot.SpringApplication [main] No active profile set, falling back to default profiles: default
2020-01-06 19:02:43,704 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 19:02:43,776 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [main] Finished Spring Data repository scanning in 67ms. Found 2 repository interfaces.
2020-01-06 19:02:44,091 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [main] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 19:02:44,123 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 19:02:44,127 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 19:02:44,137 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [main] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 19:02:44,191 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:02:44,222 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$2741b6ae] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:02:44,230 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$2d3c1ce] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:02:44,239 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$3bbb6a9b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:02:44,244 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [main] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:02:44,539 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat initialized with port(s): 8081 (http)
2020-01-06 19:02:44,553 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 19:02:44,561 INFO org.apache.juli.logging.DirectJDKLog [main] Starting service [Tomcat]
2020-01-06 19:02:44,562 INFO org.apache.juli.logging.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 19:02:44,837 INFO org.apache.juli.logging.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2020-01-06 19:02:44,837 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 1905 ms
2020-01-06 19:02:47,473 INFO org.apache.spark.internal.Logging$class [main] Running Spark version 2.4.4
2020-01-06 19:02:47,604 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 19:02:47,677 INFO org.apache.spark.internal.Logging$class [main] Submitted application: test
2020-01-06 19:02:47,734 INFO org.apache.spark.internal.Logging$class [main] Changing view acls to: Marcos.Jaramillo
2020-01-06 19:02:47,735 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls to: Marcos.Jaramillo
2020-01-06 19:02:47,736 INFO org.apache.spark.internal.Logging$class [main] Changing view acls groups to: 
2020-01-06 19:02:47,737 INFO org.apache.spark.internal.Logging$class [main] Changing modify acls groups to: 
2020-01-06 19:02:47,738 INFO org.apache.spark.internal.Logging$class [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 19:02:48,766 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'sparkDriver' on port 49896.
2020-01-06 19:02:48,785 INFO org.apache.spark.internal.Logging$class [main] Registering MapOutputTracker
2020-01-06 19:02:48,807 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManagerMaster
2020-01-06 19:02:48,809 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 19:02:48,810 INFO org.apache.spark.internal.Logging$class [main] BlockManagerMasterEndpoint up
2020-01-06 19:02:48,817 INFO org.apache.spark.internal.Logging$class [main] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-2f6c0f40-4740-43a7-a3af-5bbe5f2adfdc
2020-01-06 19:02:48,840 INFO org.apache.spark.internal.Logging$class [main] MemoryStore started with capacity 1992.0 MB
2020-01-06 19:02:48,856 INFO org.apache.spark.internal.Logging$class [main] Registering OutputCommitCoordinator
2020-01-06 19:02:48,916 INFO org.spark_project.jetty.util.log.Log [main] Logging initialized @7946ms
2020-01-06 19:02:48,973 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 19:02:48,989 INFO org.spark_project.jetty.server.Server [main] Started @8018ms
2020-01-06 19:02:49,013 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@73476e2d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 19:02:49,014 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'SparkUI' on port 4040.
2020-01-06 19:02:49,030 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@ab3b54{/jobs,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,032 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3e7da4cb{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,032 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@37ad818e{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,033 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@69a031a4{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,034 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@32da6cef{/stages,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,035 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4b9dd787{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,036 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3545c913{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,037 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@580c4c0b{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,037 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@604e8a6{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,038 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5bc44d78{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,039 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2f408960{/storage,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,039 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1516f497{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,040 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@34766f4b{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,041 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4d204b30{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,042 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6600d07d{/environment,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,043 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@44103266{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,043 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@439b0198{/executors,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,044 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@c2dab10{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,045 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6c4e11d0{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,046 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@29088d3d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,052 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3284de45{/static,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,053 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2f2a5064{/,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,055 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@43a72f0f{/api,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,055 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@18d63996{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,056 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6e6bd43b{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 19:02:49,058 INFO org.apache.spark.internal.Logging$class [main] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 19:02:49,146 INFO org.apache.spark.internal.Logging$class [main] Starting executor ID driver on host localhost
2020-01-06 19:02:49,175 INFO org.apache.spark.internal.Logging$class [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49913.
2020-01-06 19:02:49,176 INFO org.apache.spark.internal.Logging$class [main] Server created on DESKTOP-8VGF145.mshome.net:49913
2020-01-06 19:02:49,178 INFO org.apache.spark.internal.Logging$class [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 19:02:49,204 INFO org.apache.spark.internal.Logging$class [main] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49913, None)
2020-01-06 19:02:49,208 INFO org.apache.spark.internal.Logging$class [] Registering block manager DESKTOP-8VGF145.mshome.net:49913 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49913, None)
2020-01-06 19:02:49,214 INFO org.apache.spark.internal.Logging$class [main] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49913, None)
2020-01-06 19:02:49,215 INFO org.apache.spark.internal.Logging$class [main] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 49913, None)
2020-01-06 19:02:49,231 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@73973e77{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 19:02:50,237 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2020-01-06 19:02:50,238 INFO com.mongodb.diagnostics.logging.SLF4JLogger [main] Adding discovered server localhost:27017 to client view of cluster
2020-01-06 19:02:50,329 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Opened connection [connectionId{localValue:1, serverValue:14013}] to localhost:27017
2020-01-06 19:02:50,338 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 2, 1]}, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=5620700}
2020-01-06 19:02:50,340 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Discovered cluster type of STANDALONE
2020-01-06 19:02:50,461 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:02:50,470 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:02:50,472 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:02:50,473 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:02:50,623 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:02:50,624 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:02:50,625 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:02:50,625 WARN org.springframework.data.convert.CustomConversions [main] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:02:51,366 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'applicationTaskExecutor'
2020-01-06 19:02:52,045 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [main] Initializing ExecutorService 'taskScheduler'
2020-01-06 19:02:52,407 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel output
2020-01-06 19:02:52,600 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel input
2020-01-06 19:02:52,617 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel errorChannel
2020-01-06 19:02:52,712 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageChannel nullChannel
2020-01-06 19:02:52,755 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [main] Registering MessageHandler errorLogger
2020-01-06 19:02:52,804 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.input' has 1 subscriber(s).
2020-01-06 19:02:52,812 INFO org.springframework.integration.endpoint.EventDrivenConsumer [main] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 19:02:52,812 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.errorChannel' has 1 subscriber(s).
2020-01-06 19:02:52,812 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started _org.springframework.integration.errorLogger
2020-01-06 19:02:53,183 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Attempting to connect to: [localhost:5672]
2020-01-06 19:02:53,253 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [main] Created new connection: rabbitConnectionFactory#40f53ea:0/SimpleConnection@36b1b28 [delegate=amqp://guest@127.0.0.1:5672/, localPort= 49929]
2020-01-06 19:02:53,305 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'application.output' has 1 subscriber(s).
2020-01-06 19:02:53,336 INFO org.springframework.cloud.stream.binder.rabbit.provisioning.RabbitExchangeQueueProvisioner [main] declaring queue for inbound: queue.log.messages.anonymous.Bh0AhXBtTmuAjrribZ14JQ, bound to: queue.log.messages
2020-01-06 19:02:53,405 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 1 subscriber(s).
2020-01-06 19:02:53,405 INFO org.springframework.integration.channel.AbstractSubscribableChannel [main] Channel 'unknown.channel.name' has 2 subscriber(s).
2020-01-06 19:02:53,443 INFO org.springframework.integration.endpoint.AbstractEndpoint [main] started inbound.queue.log.messages.anonymous.Bh0AhXBtTmuAjrribZ14JQ
2020-01-06 19:02:53,467 INFO org.apache.juli.logging.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-8081"]
2020-01-06 19:02:53,501 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat started on port(s): 8081 (http) with context path ''
2020-01-06 19:02:53,504 INFO org.springframework.boot.StartupInfoLogger [main] Started EventGeneratorApplication in 11.2175469 seconds (JVM running for 12.533)
2020-01-06 19:02:54,686 INFO org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin [] Application shutdown requested.
2020-01-06 19:02:57,405 INFO org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin [] Application shutdown requested.
2020-01-06 19:02:57,777 INFO org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer [] Waiting for workers to finish.
2020-01-06 19:02:57,783 INFO org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer [] Successfully waited for workers to finish.
2020-01-06 19:02:57,784 INFO org.springframework.integration.endpoint.AbstractEndpoint [] stopped inbound.queue.log.messages.anonymous.Bh0AhXBtTmuAjrribZ14JQ
2020-01-06 19:02:57,802 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel queue.log.messages.anonymous.Bh0AhXBtTmuAjrribZ14JQ.errors
2020-01-06 19:02:58,004 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.queue.log.messages.anonymous.Bh0AhXBtTmuAjrribZ14JQ.errors' has 1 subscriber(s).
2020-01-06 19:02:58,005 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.queue.log.messages.anonymous.Bh0AhXBtTmuAjrribZ14JQ.errors' has 0 subscriber(s).
2020-01-06 19:02:58,011 INFO org.springframework.integration.endpoint.EventDrivenConsumer [] Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 19:02:58,011 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.errorChannel' has 0 subscriber(s).
2020-01-06 19:02:58,012 INFO org.springframework.integration.endpoint.AbstractEndpoint [] stopped _org.springframework.integration.errorLogger
2020-01-06 19:02:58,013 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Shutting down ExecutorService 'taskScheduler'
2020-01-06 19:02:58,027 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Shutting down ExecutorService 'applicationTaskExecutor'
2020-01-06 19:02:58,045 INFO org.spark_project.jetty.server.AbstractConnector [] Stopped Spark@73476e2d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 19:02:58,049 INFO org.apache.spark.internal.Logging$class [] Stopped Spark web UI at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 19:02:58,070 INFO org.apache.spark.internal.Logging$class [] MapOutputTrackerMasterEndpoint stopped!
2020-01-06 19:02:58,085 INFO org.apache.spark.internal.Logging$class [] MemoryStore cleared
2020-01-06 19:02:58,086 INFO org.apache.spark.internal.Logging$class [] BlockManager stopped
2020-01-06 19:02:58,098 INFO org.apache.spark.internal.Logging$class [] BlockManagerMaster stopped
2020-01-06 19:02:58,104 INFO org.apache.spark.internal.Logging$class [] OutputCommitCoordinator stopped!
2020-01-06 19:02:58,110 INFO org.apache.spark.internal.Logging$class [] Successfully stopped SparkContext
2020-01-06 19:02:58,111 INFO org.apache.spark.internal.Logging$class [] SparkContext already stopped.
2020-01-06 19:02:58,112 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: output
2020-01-06 19:02:58,113 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: input
2020-01-06 19:02:58,113 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: errorChannel
2020-01-06 19:02:58,113 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: nullChannel
2020-01-06 19:02:58,114 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Summary on shutdown: _org.springframework.integration.errorLogger.handler
2020-01-06 19:02:58,694 INFO org.apache.spark.internal.Logging$class [] Shutdown hook called
2020-01-06 19:02:58,695 INFO org.apache.spark.internal.Logging$class [] Deleting directory C:\Users\Marcos.Jaramillo\AppData\Local\Temp\spark-2547e1ed-c5ac-4ffa-8104-5c3de4f236c8
2020-01-06 19:04:11,288 INFO org.springframework.boot.StartupInfoLogger [] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 37136 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 19:04:11,294 INFO org.springframework.boot.SpringApplication [] No active profile set, falling back to default profiles: default
2020-01-06 19:04:12,074 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 19:04:12,157 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [] Finished Spring Data repository scanning in 77ms. Found 2 repository interfaces.
2020-01-06 19:04:12,535 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 19:04:12,577 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 19:04:12,583 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 19:04:12,595 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 19:04:12,648 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:04:12,678 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$11e9cb99] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:04:12,687 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$ed7bd6b9] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:04:12,695 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$26637f86] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:04:12,702 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:04:13,016 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [] Tomcat initialized with port(s): 8081 (http)
2020-01-06 19:04:13,029 INFO org.apache.juli.logging.DirectJDKLog [] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 19:04:13,038 INFO org.apache.juli.logging.DirectJDKLog [] Starting service [Tomcat]
2020-01-06 19:04:13,038 INFO org.apache.juli.logging.DirectJDKLog [] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 19:04:13,246 INFO org.apache.juli.logging.DirectJDKLog [] Initializing Spring embedded WebApplicationContext
2020-01-06 19:04:13,246 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [] Root WebApplicationContext: initialization completed in 1852 ms
2020-01-06 19:04:15,791 INFO org.apache.spark.internal.Logging$class [] Running Spark version 2.4.4
2020-01-06 19:04:15,926 WARN org.apache.hadoop.util.NativeCodeLoader [] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 19:04:16,001 INFO org.apache.spark.internal.Logging$class [] Submitted application: test
2020-01-06 19:04:16,056 INFO org.apache.spark.internal.Logging$class [] Changing view acls to: Marcos.Jaramillo
2020-01-06 19:04:16,057 INFO org.apache.spark.internal.Logging$class [] Changing modify acls to: Marcos.Jaramillo
2020-01-06 19:04:16,058 INFO org.apache.spark.internal.Logging$class [] Changing view acls groups to: 
2020-01-06 19:04:16,059 INFO org.apache.spark.internal.Logging$class [] Changing modify acls groups to: 
2020-01-06 19:04:16,060 INFO org.apache.spark.internal.Logging$class [] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 19:04:17,126 INFO org.apache.spark.internal.Logging$class [] Successfully started service 'sparkDriver' on port 50116.
2020-01-06 19:04:17,143 INFO org.apache.spark.internal.Logging$class [] Registering MapOutputTracker
2020-01-06 19:04:17,166 INFO org.apache.spark.internal.Logging$class [] Registering BlockManagerMaster
2020-01-06 19:04:17,169 INFO org.apache.spark.internal.Logging$class [] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 19:04:17,170 INFO org.apache.spark.internal.Logging$class [] BlockManagerMasterEndpoint up
2020-01-06 19:04:17,177 INFO org.apache.spark.internal.Logging$class [] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-b9004858-6879-4d86-8cb5-424b7ff55742
2020-01-06 19:04:17,204 INFO org.apache.spark.internal.Logging$class [] MemoryStore started with capacity 1992.0 MB
2020-01-06 19:04:17,224 INFO org.apache.spark.internal.Logging$class [] Registering OutputCommitCoordinator
2020-01-06 19:04:17,318 INFO org.spark_project.jetty.util.log.Log [] Logging initialized @8019ms
2020-01-06 19:04:17,383 INFO org.spark_project.jetty.server.Server [] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 19:04:17,397 INFO org.spark_project.jetty.server.Server [] Started @8098ms
2020-01-06 19:04:17,423 INFO org.spark_project.jetty.server.AbstractConnector [] Started ServerConnector@6414eb98{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 19:04:17,423 INFO org.apache.spark.internal.Logging$class [] Successfully started service 'SparkUI' on port 4040.
2020-01-06 19:04:17,447 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@18174bd9{/jobs,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,448 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@5e405eaf{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,449 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@4981b83{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,451 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@5e0602ff{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,451 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@1a865ebf{/stages,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,452 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@6b3d3e57{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,453 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@15251cc2{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,455 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@40ef385f{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,456 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@1a4c6e74{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,457 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@28d728f1{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,458 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@51d6c42d{/storage,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,459 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@68423388{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,459 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@1104cf3a{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,460 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@85fd4b{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,462 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@6715a6da{/environment,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,463 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@1eb207c3{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,464 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@29f86630{/executors,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,464 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@6b8a9e1{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,465 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@4c51fc9a{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,466 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@425376cc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,472 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@28705150{/static,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,473 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@7a05cdc8{/,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,474 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@5f3fafca{/api,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,475 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@45689582{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,476 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@73db1a6{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 19:04:17,479 INFO org.apache.spark.internal.Logging$class [] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 19:04:17,575 INFO org.apache.spark.internal.Logging$class [] Starting executor ID driver on host localhost
2020-01-06 19:04:17,609 INFO org.apache.spark.internal.Logging$class [] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50134.
2020-01-06 19:04:17,610 INFO org.apache.spark.internal.Logging$class [] Server created on DESKTOP-8VGF145.mshome.net:50134
2020-01-06 19:04:17,612 INFO org.apache.spark.internal.Logging$class [] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 19:04:17,643 INFO org.apache.spark.internal.Logging$class [] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 50134, None)
2020-01-06 19:04:17,647 INFO org.apache.spark.internal.Logging$class [] Registering block manager DESKTOP-8VGF145.mshome.net:50134 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 50134, None)
2020-01-06 19:04:17,654 INFO org.apache.spark.internal.Logging$class [] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 50134, None)
2020-01-06 19:04:17,655 INFO org.apache.spark.internal.Logging$class [] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 50134, None)
2020-01-06 19:04:17,673 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@6eaf6ced{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 19:04:18,783 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2020-01-06 19:04:18,783 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Adding discovered server localhost:27017 to client view of cluster
2020-01-06 19:04:18,875 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Opened connection [connectionId{localValue:1, serverValue:14017}] to localhost:27017
2020-01-06 19:04:18,886 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 2, 1]}, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=7047200}
2020-01-06 19:04:18,889 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Discovered cluster type of STANDALONE
2020-01-06 19:04:18,995 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:04:19,004 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:04:19,006 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:04:19,007 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:04:19,126 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:04:19,127 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:04:19,128 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:04:19,128 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:04:19,686 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Initializing ExecutorService 'applicationTaskExecutor'
2020-01-06 19:04:20,081 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Initializing ExecutorService 'taskScheduler'
2020-01-06 19:04:20,293 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel output
2020-01-06 19:04:20,383 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel input
2020-01-06 19:04:20,394 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel nullChannel
2020-01-06 19:04:20,410 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel errorChannel
2020-01-06 19:04:20,465 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageHandler errorLogger
2020-01-06 19:04:20,496 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.input' has 1 subscriber(s).
2020-01-06 19:04:20,502 INFO org.springframework.integration.endpoint.EventDrivenConsumer [] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 19:04:20,503 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.errorChannel' has 1 subscriber(s).
2020-01-06 19:04:20,503 INFO org.springframework.integration.endpoint.AbstractEndpoint [] started _org.springframework.integration.errorLogger
2020-01-06 19:04:20,715 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [] Attempting to connect to: [localhost:5672]
2020-01-06 19:04:20,750 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [] Created new connection: rabbitConnectionFactory#41843b88:0/SimpleConnection@c4f6d5b [delegate=amqp://guest@127.0.0.1:5672/, localPort= 50136]
2020-01-06 19:04:20,787 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.output' has 1 subscriber(s).
2020-01-06 19:04:20,808 INFO org.springframework.cloud.stream.binder.rabbit.provisioning.RabbitExchangeQueueProvisioner [] declaring queue for inbound: queue.log.messages.anonymous.QBWaDwBRSz2j1rxj_pghjQ, bound to: queue.log.messages
2020-01-06 19:04:20,830 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'unknown.channel.name' has 1 subscriber(s).
2020-01-06 19:04:20,830 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'unknown.channel.name' has 2 subscriber(s).
2020-01-06 19:04:20,852 INFO org.springframework.integration.endpoint.AbstractEndpoint [] started inbound.queue.log.messages.anonymous.QBWaDwBRSz2j1rxj_pghjQ
2020-01-06 19:04:20,869 INFO org.apache.juli.logging.DirectJDKLog [] Starting ProtocolHandler ["http-nio-8081"]
2020-01-06 19:04:20,889 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [] Tomcat started on port(s): 8081 (http) with context path ''
2020-01-06 19:04:20,891 INFO org.springframework.boot.StartupInfoLogger [] Started EventGeneratorApplication in 10.2666681 seconds (JVM running for 11.592)
2020-01-06 19:06:02,014 INFO org.springframework.boot.StartupInfoLogger [] Starting EventGeneratorApplication on DESKTOP-8VGF145 with PID 19592 (D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator\target\classes started by Marcos.Jaramillo in D:\Proyectos\Translados\GitHub\mine\EventGenerator\EventGenerator)
2020-01-06 19:06:02,018 INFO org.springframework.boot.SpringApplication [] No active profile set, falling back to default profiles: default
2020-01-06 19:06:02,805 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [] Bootstrapping Spring Data repositories in DEFAULT mode.
2020-01-06 19:06:02,881 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [] Finished Spring Data repository scanning in 70ms. Found 2 repository interfaces.
2020-01-06 19:06:03,240 INFO org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor [] @Bean method BinderFactoryConfiguration.implicitFunctionBinder is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2020-01-06 19:06:03,273 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2020-01-06 19:06:03,277 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [] No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2020-01-06 19:06:03,291 INFO org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor [] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2020-01-06 19:06:03,349 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:06:03,378 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$52f4b338] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:06:03,386 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$2e86be58] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:06:03,394 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$676e6725] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:06:03,400 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [] Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-01-06 19:06:03,816 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [] Tomcat initialized with port(s): 8081 (http)
2020-01-06 19:06:03,836 INFO org.apache.juli.logging.DirectJDKLog [] Initializing ProtocolHandler ["http-nio-8081"]
2020-01-06 19:06:03,850 INFO org.apache.juli.logging.DirectJDKLog [] Starting service [Tomcat]
2020-01-06 19:06:03,851 INFO org.apache.juli.logging.DirectJDKLog [] Starting Servlet engine: [Apache Tomcat/9.0.26]
2020-01-06 19:06:04,065 INFO org.apache.juli.logging.DirectJDKLog [] Initializing Spring embedded WebApplicationContext
2020-01-06 19:06:04,065 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [] Root WebApplicationContext: initialization completed in 1953 ms
2020-01-06 19:06:06,700 INFO org.apache.spark.internal.Logging$class [] Running Spark version 2.4.4
2020-01-06 19:06:06,839 WARN org.apache.hadoop.util.NativeCodeLoader [] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-06 19:06:06,924 INFO org.apache.spark.internal.Logging$class [] Submitted application: test
2020-01-06 19:06:06,985 INFO org.apache.spark.internal.Logging$class [] Changing view acls to: Marcos.Jaramillo
2020-01-06 19:06:06,986 INFO org.apache.spark.internal.Logging$class [] Changing modify acls to: Marcos.Jaramillo
2020-01-06 19:06:06,987 INFO org.apache.spark.internal.Logging$class [] Changing view acls groups to: 
2020-01-06 19:06:06,988 INFO org.apache.spark.internal.Logging$class [] Changing modify acls groups to: 
2020-01-06 19:06:06,989 INFO org.apache.spark.internal.Logging$class [] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Marcos.Jaramillo); groups with view permissions: Set(); users  with modify permissions: Set(Marcos.Jaramillo); groups with modify permissions: Set()
2020-01-06 19:06:08,233 INFO org.apache.spark.internal.Logging$class [] Successfully started service 'sparkDriver' on port 50405.
2020-01-06 19:06:08,255 INFO org.apache.spark.internal.Logging$class [] Registering MapOutputTracker
2020-01-06 19:06:08,276 INFO org.apache.spark.internal.Logging$class [] Registering BlockManagerMaster
2020-01-06 19:06:08,279 INFO org.apache.spark.internal.Logging$class [] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-06 19:06:08,280 INFO org.apache.spark.internal.Logging$class [] BlockManagerMasterEndpoint up
2020-01-06 19:06:08,288 INFO org.apache.spark.internal.Logging$class [] Created local directory at C:\Users\Marcos.Jaramillo\AppData\Local\Temp\blockmgr-7e981946-7878-451a-a53e-63749d95d439
2020-01-06 19:06:08,313 INFO org.apache.spark.internal.Logging$class [] MemoryStore started with capacity 1992.0 MB
2020-01-06 19:06:08,331 INFO org.apache.spark.internal.Logging$class [] Registering OutputCommitCoordinator
2020-01-06 19:06:08,397 INFO org.spark_project.jetty.util.log.Log [] Logging initialized @8442ms
2020-01-06 19:06:08,465 INFO org.spark_project.jetty.server.Server [] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-06 19:06:08,480 INFO org.spark_project.jetty.server.Server [] Started @8525ms
2020-01-06 19:06:08,512 INFO org.spark_project.jetty.server.AbstractConnector [] Started ServerConnector@16b713dd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-06 19:06:08,513 INFO org.apache.spark.internal.Logging$class [] Successfully started service 'SparkUI' on port 4040.
2020-01-06 19:06:08,537 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@31d8352e{/jobs,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,538 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@7bbc11ed{/jobs/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,539 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@7d741200{/jobs/job,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,540 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@6af02de0{/jobs/job/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,541 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@3749c6ac{/stages,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,541 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@9cdf13e{/stages/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,542 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@3bede349{/stages/stage,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,544 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@129b0ed{/stages/stage/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,545 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@4ccf1d3e{/stages/pool,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,546 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@75ff2b6d{/stages/pool/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,546 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@20a7ce0{/storage,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,547 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@4ee80a94{/storage/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,548 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@7afac89a{/storage/rdd,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,549 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@76d220eb{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,550 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@276eafad{/environment,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,550 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@29dcad7e{/environment/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,551 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@5ce1ec7{/executors,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,551 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@627cb3ed{/executors/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,552 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@30bd6bc8{/executors/threadDump,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,552 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@7c4697fc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,557 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@90b9695{/static,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,558 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@23243bc0{/,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,559 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@770c3ca2{/api,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,560 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@659565ed{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,560 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@481eb705{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-01-06 19:06:08,562 INFO org.apache.spark.internal.Logging$class [] Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-8VGF145.mshome.net:4040
2020-01-06 19:06:08,649 INFO org.apache.spark.internal.Logging$class [] Starting executor ID driver on host localhost
2020-01-06 19:06:08,681 INFO org.apache.spark.internal.Logging$class [] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50422.
2020-01-06 19:06:08,683 INFO org.apache.spark.internal.Logging$class [] Server created on DESKTOP-8VGF145.mshome.net:50422
2020-01-06 19:06:08,685 INFO org.apache.spark.internal.Logging$class [] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-01-06 19:06:08,714 INFO org.apache.spark.internal.Logging$class [] Registering BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 50422, None)
2020-01-06 19:06:08,718 INFO org.apache.spark.internal.Logging$class [] Registering block manager DESKTOP-8VGF145.mshome.net:50422 with 1992.0 MB RAM, BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 50422, None)
2020-01-06 19:06:08,724 INFO org.apache.spark.internal.Logging$class [] Registered BlockManager BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 50422, None)
2020-01-06 19:06:08,725 INFO org.apache.spark.internal.Logging$class [] Initialized BlockManager: BlockManagerId(driver, DESKTOP-8VGF145.mshome.net, 50422, None)
2020-01-06 19:06:08,742 INFO org.spark_project.jetty.server.handler.ContextHandler [] Started o.s.j.s.ServletContextHandler@f4aec23{/metrics/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:09,828 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2020-01-06 19:06:09,829 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Adding discovered server localhost:27017 to client view of cluster
2020-01-06 19:06:09,927 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Opened connection [connectionId{localValue:1, serverValue:14021}] to localhost:27017
2020-01-06 19:06:09,935 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 2, 1]}, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4324600}
2020-01-06 19:06:09,938 INFO com.mongodb.diagnostics.logging.SLF4JLogger [] Discovered cluster type of STANDALONE
2020-01-06 19:06:10,021 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:06:10,027 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:06:10,028 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:06:10,029 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:06:10,133 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:06:10,134 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:06:10,135 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.LocalDateTime to class java.time.Instant as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:06:10,135 WARN org.springframework.data.convert.CustomConversions [] Registering converter from class java.time.Instant to class java.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might wanna check you annotation setup at the converter implementation.
2020-01-06 19:06:10,689 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Initializing ExecutorService 'applicationTaskExecutor'
2020-01-06 19:06:11,079 INFO org.springframework.scheduling.concurrent.ExecutorConfigurationSupport [] Initializing ExecutorService 'taskScheduler'
2020-01-06 19:06:11,294 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel output
2020-01-06 19:06:11,398 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel nullChannel
2020-01-06 19:06:11,417 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel errorChannel
2020-01-06 19:06:11,474 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageChannel input
2020-01-06 19:06:11,485 INFO org.springframework.integration.monitor.IntegrationMBeanExporter [] Registering MessageHandler errorLogger
2020-01-06 19:06:11,518 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.input' has 1 subscriber(s).
2020-01-06 19:06:11,523 INFO org.springframework.integration.endpoint.EventDrivenConsumer [] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2020-01-06 19:06:11,523 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.errorChannel' has 1 subscriber(s).
2020-01-06 19:06:11,524 INFO org.springframework.integration.endpoint.AbstractEndpoint [] started _org.springframework.integration.errorLogger
2020-01-06 19:06:11,742 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [] Attempting to connect to: [localhost:5672]
2020-01-06 19:06:11,776 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [] Created new connection: rabbitConnectionFactory#7f69a16b:0/SimpleConnection@7a725c89 [delegate=amqp://guest@127.0.0.1:5672/, localPort= 50434]
2020-01-06 19:06:11,807 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'application.output' has 1 subscriber(s).
2020-01-06 19:06:11,825 INFO org.springframework.cloud.stream.binder.rabbit.provisioning.RabbitExchangeQueueProvisioner [] declaring queue for inbound: queue.log.messages.anonymous.KHnqIDyWR02m4R9EfbAi8w, bound to: queue.log.messages
2020-01-06 19:06:11,849 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'unknown.channel.name' has 1 subscriber(s).
2020-01-06 19:06:11,849 INFO org.springframework.integration.channel.AbstractSubscribableChannel [] Channel 'unknown.channel.name' has 2 subscriber(s).
2020-01-06 19:06:11,872 INFO org.springframework.integration.endpoint.AbstractEndpoint [] started inbound.queue.log.messages.anonymous.KHnqIDyWR02m4R9EfbAi8w
2020-01-06 19:06:11,887 INFO org.apache.juli.logging.DirectJDKLog [] Starting ProtocolHandler ["http-nio-8081"]
2020-01-06 19:06:11,905 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [] Tomcat started on port(s): 8081 (http) with context path ''
2020-01-06 19:06:11,906 INFO org.springframework.boot.StartupInfoLogger [] Started EventGeneratorApplication in 10.5696136 seconds (JVM running for 11.951)
2020-01-06 19:06:25,712 INFO com.ternium.core.eventgenerator.stream.RabbitStream [] Received Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 19:06:25,713 INFO com.ternium.core.eventgenerator.service.EventGeneratorService [84] Thread 84 Processing Message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 19:06:25,723 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [] Attempting to connect to: [localhost:5672]
2020-01-06 19:06:25,735 INFO org.springframework.amqp.rabbit.connection.AbstractConnectionFactory [] Created new connection: rabbitConnectionFactory.publisher#5df2ffb6:0/SimpleConnection@58bb1471 [delegate=amqp://guest@127.0.0.1:5672/, localPort= 50460]
2020-01-06 19:06:25,735 INFO org.springframework.amqp.rabbit.core.RabbitAdmin [] Auto-declaring a non-durable, auto-delete, or exclusive Queue (queue.log.messages.anonymous.KHnqIDyWR02m4R9EfbAi8w) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost.
2020-01-06 19:06:25,786 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [84] Recieve message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 19:06:25,787 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [84] SPARK Context Builded
2020-01-06 19:06:25,788 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [84] jsonData:=[	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}]
2020-01-06 19:06:27,153 INFO org.apache.spark.internal.Logging$class [84] Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/Proyectos/Translados/GitHub/mine/EventGenerator/EventGenerator/spark-warehouse').
2020-01-06 19:06:27,154 INFO org.apache.spark.internal.Logging$class [84] Warehouse path is 'file:/D:/Proyectos/Translados/GitHub/mine/EventGenerator/EventGenerator/spark-warehouse'.
2020-01-06 19:06:27,161 INFO org.spark_project.jetty.server.handler.ContextHandler [84] Started o.s.j.s.ServletContextHandler@123536c0{/SQL,null,AVAILABLE,@Spark}
2020-01-06 19:06:27,161 INFO org.spark_project.jetty.server.handler.ContextHandler [84] Started o.s.j.s.ServletContextHandler@578cafe1{/SQL/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:27,163 INFO org.spark_project.jetty.server.handler.ContextHandler [84] Started o.s.j.s.ServletContextHandler@35d95208{/SQL/execution,null,AVAILABLE,@Spark}
2020-01-06 19:06:27,163 INFO org.spark_project.jetty.server.handler.ContextHandler [84] Started o.s.j.s.ServletContextHandler@6a46055d{/SQL/execution/json,null,AVAILABLE,@Spark}
2020-01-06 19:06:27,164 INFO org.spark_project.jetty.server.handler.ContextHandler [84] Started o.s.j.s.ServletContextHandler@242547dd{/static/sql,null,AVAILABLE,@Spark}
2020-01-06 19:06:27,435 INFO org.apache.spark.internal.Logging$class [84] Registered StateStoreCoordinator endpoint
2020-01-06 19:06:27,676 INFO org.apache.spark.internal.Logging$class [84] Code generated in 193.4157 ms
2020-01-06 19:06:28,217 INFO org.apache.spark.internal.Logging$class [84] Code generated in 11.6269 ms
2020-01-06 19:06:28,236 INFO org.apache.spark.internal.Logging$class [84] Code generated in 8.5892 ms
2020-01-06 19:06:28,255 INFO com.ternium.core.eventgenerator.visitor.impl.FilterVisitor [84] data:=[value: string]
2020-01-06 19:06:28,257 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] Going to call the group FilterRules
2020-01-06 19:06:28,336 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=Transformation, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 19:06:28,338 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [84] Apply Data Transform to 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
2020-01-06 19:06:28,338 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] Going to call the group Translator
2020-01-06 19:06:28,357 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] respuesta de objeto:Message [domain=Produccion, event=null, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=null, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=null, expectedTrxs=null, jsonQueryChild=null, tagChild=null, master=null, outputDataFields=null, eventDomain=null]
2020-01-06 19:06:28,358 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] Going to call the group Transformation
2020-01-06 19:06:28,382 INFO com.ternium.core.eventgenerator.messenger.impl.RulesMessenger [84] respuesta de objeto:Message [domain=Produccion, event=ComplexEvent, timestamp=1574386121, data={Documentos=[], DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_3=ValorPruebaA_3}, topic=null, ruleName=TopicAssignment, trx=PruebaA, translatorMap=null, jsonQuery=null, cache=true, expectedTrxs=1, jsonQueryChild={"_id.domain":"Produccion","_id.trx":"PruebaB","data.KeyPrueba":"${Id}"}, tagChild=Documentos, master=true, outputDataFields=null, eventDomain=Produccion1]
2020-01-06 19:06:28,448 INFO com.mongodb.diagnostics.logging.SLF4JLogger [84] Opened connection [connectionId{localValue:2, serverValue:14023}] to localhost:27017
2020-01-06 19:06:28,477 INFO com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor [84] Data Already Exist
2020-01-06 19:06:28,480 ERROR com.ternium.core.eventgenerator.service.EventGeneratorService [84] Error while processing message 	{
		"domain" : "Produccion",
		"timestamp" : "1574386121",
		"trx" : "PruebaA",
		"data" : {
			"DatoPruebaA_1" : "ValorPruebaA_1",
			"DatoPruebaA_2" : "ValorPruebaA_2",
			"DatoPruebaA_3" : "ValorPruebaA_3",
			"Documentos" : [ 
				{"Id": "0003", "Desc" : "XXX"},
				{"Id": "0004", "Desc" : "YYY"}
			]
		}
	}
com.ternium.core.eventgenerator.exception.DataAlreadyExistException: Data Already Exist for Transaction [id=TransactionPK [domain=Produccion, trx=PruebaA, timestamp=1574386121], data={DatoPruebaA_1=ValorPruebaA_1, DatoPruebaA_2=ValorPruebaA_2, DatoPruebaA_3=ValorPruebaA_3, Documentos=[{Id=0003, Desc=XXX}, {Id=0004, Desc=YYY}]}]
	at com.ternium.core.eventgenerator.visitor.impl.DataTransformVisitor.visit(DataTransformVisitor.java:119)
	at com.ternium.core.eventgenerator.visitor.element.EventElement.accept(EventElement.java:27)
	at com.ternium.core.eventgenerator.service.EventGeneratorService.lambda$0(EventGeneratorService.java:42)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2020-01-06 19:36:09,051 INFO org.apache.spark.internal.Logging$class [] Cleaned accumulator 0
